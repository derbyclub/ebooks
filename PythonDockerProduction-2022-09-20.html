<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Itamar Turner-Trauring" />
  <title>Python on Docker Production Handbook</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link href="https://fonts.googleapis.com/css?family=Rosario:400,400i,700|Ubuntu+Mono:400,700" rel="stylesheet"> <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <style>
  body {
     font-family: 'Rosario', sans-serif;
     max-width: 42rem;
     margin: 4rem auto;
     font-size: 20px;
     line-height: 1.4;
  }
  pre, code {
     font-family: 'Ubuntu Mono', monospace;
     font-size: 90%;
  }
  a {
      text-decoration: underline !important;
  }
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Python on Docker Production Handbook</h1>
<p class="author">Itamar Turner-Trauring</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#legal-disclaimer">Legal disclaimer</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#plan">A phased implementation plan</a>
<ul>
<li><a href="#step-1-it-works">Step 1: It works</a></li>
<li><a href="#step-2-basic-security">Step 2: Basic security</a></li>
<li><a href="#step-3-running-in-ci">Step 3: Running in CI</a></li>
<li><a href="#step-4-easier-to-debug">Step 4: Easier to debug</a></li>
<li><a href="#step-5-additional-operational-correctness">Step 5: Additional operational correctness</a></li>
<li><a href="#step-6-reproducible-builds">Step 6: Reproducible builds</a></li>
<li><a href="#step-7-faster-builds">Step 7: Faster builds</a></li>
<li><a href="#step-8-smaller-images">Step 8: Smaller images</a></li>
</ul></li>
<li><a href="#docker-versions-and-buildkit">Docker versions and BuildKit</a>
<ul>
<li><a href="#docker-20.10">Docker 20.10</a></li>
<li><a href="#buildkit">BuildKit</a></li>
<li><a href="#podman">Podman</a></li>
<li><a href="#the-problem-with-arm-macs">The problem with ARM Macs</a></li>
</ul></li>
<li><a href="#best-practices-security">Best practices: Security</a>
<ul>
<li><a href="#no-root">Don’t run as root</a></li>
<li><a href="#port-1024">Don’t listen on ports &lt; 1024</a></li>
<li><a href="#no-capabilities">Run your container with no capabilities</a></li>
<li><a href="#update-system-packages">Update system packages</a></li>
<li><a href="#weekly-rebuild">∞ Rebuild without caching and redeploy at least weekly ∞</a></li>
<li><a href="#apply-security-fixes">∞ Apply security fixes when they come out ∞</a></li>
<li><a href="#security-scanners">Run security scanners</a></li>
<li><a href="#secret-files">Don’t leak secret files</a></li>
<li><a href="#runtime-secrets">Don’t leak runtime secrets</a></li>
<li><a href="#build-secrets">Don’t leak build secrets</a></li>
<li><a href="#compose-secrets">Using BuildKit secrets from Docker Compose v1</a></li>
<li><a href="#using-build-secrets-in-docker-compose-v2">Using build secrets in Docker Compose v2</a></li>
<li><a href="#use-host-ssh-keys-with-buildkit-ssh-agent-forwarding">Use host SSH keys with BuildKit <code>ssh-agent</code> forwarding</a></li>
<li><a href="#optional-pre-populate-ssh-known-hosts">Optional: Pre-populate SSH known hosts</a></li>
</ul></li>
<li><a href="#best-practices-running-in-ci">Best practices: Running in CI</a>
<ul>
<li><a href="#smoke-test">Add a smoke test for your image</a></li>
<li><a href="#additional-checks">Additional checks: <code>hadolint</code>, size checks</a></li>
<li><a href="#tag-branch">Tag images based on the version control branch</a></li>
<li><a href="#latest-tag">Don’t rely on the <code>latest</code> tag</a></li>
<li><a href="#pull-in-ci">Warm up the build cache</a></li>
<li><a href="#pull-in-ci-2">Warm up the build cache for per-branch builds</a></li>
<li><a href="#optional-self-warming-cache-with-buildkit">Optional: Self-warming cache with BuildKit</a></li>
</ul></li>
<li><a href="#best-practices-make-debugging-easier">Best practices: Make debugging easier</a>
<ul>
<li><a href="#stdout-logs">Write logs to <code>stdout</code> or <code>stderr</code></a></li>
<li><a href="#faulthandler">Prepare for C crashes</a></li>
<li><a href="#identifiable">Record the build’s version control revision and branch</a></li>
<li><a href="#useful-tools">Optional: Pre-install useful tools</a></li>
</ul></li>
<li><a href="#best-practices-correct-operation">Best practices: Correct operation</a>
<ul>
<li><a href="#networkbind">Have public ports listen on <code>0.0.0.0</code></a></li>
<li><a href="#bash">Avoid bash, or at least use bash strict mode and <code>shellcheck</code></a></li>
<li><a href="#shutdown">Ensure fast shutdowns</a></li>
<li><a href="#init">Add an <code>init</code> process</a></li>
<li><a href="#deb-interactive">Set a non-interactive frontend for Debian/Ubuntu package installs</a></li>
<li><a href="#health-checks">Add health checks</a></li>
<li><a href="#bytecode">Pre-compile bytecode for faster startup</a></li>
</ul></li>
<li><a href="#best-practices-reproducible-builds">Best practices: Reproducible builds</a>
<ul>
<li><a href="#base">Choose a stable base image and tag</a></li>
<li><a href="#redhat-compatible-base-images">RedHat-compatible base images</a></li>
<li><a href="#pin-python">Pin your Python dependencies</a></li>
<li><a href="#update-dependencies">∞ Update all pinned dependencies once a month ∞</a></li>
<li><a href="#pin-system">Optional: Pin system packages</a></li>
<li><a href="#custom-base-image">Optional: Create a custom base image</a></li>
</ul></li>
<li><a href="#best-practices-faster-builds">Best practices: Faster builds</a>
<ul>
<li><a href="#no-alpine">Don’t use Alpine Linux</a></li>
<li><a href="#copy-late"><code>COPY</code> in files only when needed</a></li>
<li><a href="#install-dependencies-first">Install dependencies separately from your code</a></li>
<li><a href="#arg-late">Use <code>ARG</code> only when needed</a></li>
<li><a href="#use-docker-build---label-instead-of-label">Use <code>docker build --label</code> instead of <code>LABEL</code></a></li>
</ul></li>
<li><a href="#best-practices-small-images">Best practices: Small images</a>
<ul>
<li><a href="#temporary-files">Keep temporary files from ending up in a layer</a></li>
<li><a href="#dive">Find large layers and files with <code>dive</code></a></li>
<li><a href="#dockerignore">Add files to <code>.dockerignore</code></a></li>
<li><a href="#git-dockerignore">Add <code>.git</code> to <code>.dockerignore</code> (and some alternatives when you can’t)</a></li>
<li><a href="#chown">Avoid extra chowns</a></li>
<li><a href="#system-packages-clean">Don’t install unnecessary system packages, and clean up when you’re done</a></li>
<li><a href="#smaller-pip">Disable pip caching</a></li>
<li><a href="#package-cache-buildkit">Optional: Caching installed packages using BuildKit or Podman</a></li>
<li><a href="#unnecessary-files">Optional: Remove files you don’t need</a></li>
</ul></li>
<li><a href="#best-practices-application-and-tool-specific">Best practices: Application and tool-specific</a>
<ul>
<li><a href="#using-a-virtualenv-in-your-dockerfile">Using a virtualenv in your <code>Dockerfile</code></a></li>
<li><a href="#dont-run-database-upgrades-on-startup">Don’t run database upgrades on startup</a></li>
<li><a href="#slow-queries">Make sure slow queries don’t break health checks</a></li>
<li><a href="#enable-running-other-commands-via-the-command-line">Enable running other commands via the command-line</a></li>
<li><a href="#gunicorn">Configure the Gunicorn web server correctly</a></li>
<li><a href="#uwsgi">Configure the uWSGI web server correctly</a></li>
<li><a href="#heroku">Respect the <code>PORT</code> environment variable on Heroku and Google Cloud Run</a></li>
</ul></li>
<li><a href="#conda">Best practices: Conda</a>
<ul>
<li><a href="#using-a-conda-environment-in-your-dockerfile">Using a Conda environment in your <code>Dockerfile</code></a></li>
<li><a href="#conda-environments-require-activation">Conda environments require activation</a></li>
<li><a href="#reproducible-builds-with-conda-lock">Reproducible builds with <code>conda-lock</code></a></li>
<li><a href="#make-conda-images-smaller-with-conda-clean">Make Conda images smaller with <code>conda clean</code></a></li>
<li><a href="#make-conda-images-smaller-by-using-openblas">Make Conda images smaller by using OpenBLAS</a></li>
<li><a href="#even-smaller-conda-images-with-conda-pack-and-multi-stage-builds">Even smaller Conda images with <code>conda-pack</code> and multi-stage builds</a></li>
<li><a href="#faster-installs-with-mamba">Faster installs with Mamba</a></li>
<li><a href="#security-scans-for-conda-environments">Security scans for Conda environments</a></li>
</ul></li>
<li><a href="#pipenv">Best practices: Pipenv</a>
<ul>
<li><a href="#install-pipenv-separately-from-your-application-code">Install Pipenv separately from your application code</a></li>
<li><a href="#installing-dependencies-inside-a-container">Installing dependencies inside a container</a></li>
</ul></li>
<li><a href="#poetry">Best practices: Poetry</a>
<ul>
<li><a href="#install-poetry-separately-from-your-application-code">Install Poetry separately from your application code</a></li>
<li><a href="#installing-outside-of-poetrys-managed-virtualenvs">Installing outside of Poetry’s managed virtualenvs</a></li>
<li><a href="#poetry-dev-depencies">Don’t install development dependencies (unless you want to)</a></li>
<li><a href="#poetry-dependencies-first">Speed up rebuilds by installing dependencies separately</a></li>
<li><a href="#poetry-version-vs-caching">Application version changes can lead to slow rebuilds</a></li>
</ul></li>
<li><a href="#multi-stage">Best practices: Multi-stage builds</a>
<ul>
<li><a href="#omit-build-dependencies-from-your-runtime-image">Omit build dependencies from your runtime image</a></li>
<li><a href="#use-a-virtualenv-to-make-copying-across-stages-easier">Use a virtualenv to make copying across stages easier</a></li>
<li><a href="#avoid-unnecessary-complete-rebuilds">Avoid unnecessary complete rebuilds</a></li>
<li><a href="#optional-use-buildkit-for-faster-builds">Optional: Use BuildKit for faster builds</a></li>
<li><a href="#optional-optimizing-image-size-even-further">Optional: Optimizing image size even further</a></li>
</ul></li>
<li><a href="#some-final-recommendations">Some final recommendations</a></li>
<li><a href="#changelog">Changelog</a></li>
</ul>
</nav>
<h1 class="unnumbered" id="legal-disclaimer">Legal disclaimer</h1>
<p>Copyright © 2021 Hyphenated Enterprises LLC. All rights reserved.</p>
<p><strong>This quickstart and the information it contains are provided “as is”, without warranties of any kind, including without limitation the implied warranties of merchantability or fitness for any particular purpose. In no event shall the author, Itamar Turner-Trauring, or the copyright owner, Hyphenated Enterprises LLC, or any of their employees, agents or affiliates, be liable for any claim, costs, expenses, damages or other liability, whether under principles of contract, tort or otherwise, arising from, out of or in connection with the use of or reliance on the information contained in this handbook.</strong></p>
<h1 class="unnumbered" id="introduction">Introduction</h1>
<p>Building production-ready Docker images isn’t easy: there’s a huge list of details you need to remember and get right. The goal of this handbook is therefore to get you going as quickly as possible, while still providing a reference to all the relevant details.</p>
<p>How to read this guide:</p>
<ol type="1">
<li>Read the next chapter, which presents a possible implementation plan.</li>
<li>Skim the guide, so you get a sense of all of the best practices; not all of them are listed in the implementation plan.</li>
<li>Go back to the implementation and create your own, situation-specific plan with the best practices you actually care about.</li>
<li>Start packaging!</li>
<li>Refer back to the guide when you need additional details.</li>
</ol>
<p>A few of the best practices are marked with <strong>∞</strong> (infinity) symbols, indicating they are ongoing processes. These tasks require periodic attention, even after you’ve finished creating and deploying your image.</p>
<p>If you have any questions or suggestions, please email me at <a href="mailto:itamar@pythonspeed.com">itamar@pythonspeed.com</a>.</p>
<p>—Itamar Turner-Trauring</p>
<h1 id="plan">A phased implementation plan</h1>
<p>There are many best practices to follow, and some are more important than others. What follows is a proposed order of implementation for your Docker packaging, with the presumption that your goal is to get something working as quickly as possible.</p>
<p>To summarize the proposed order:</p>
<ol type="1">
<li>Get something minimal working, so that it’s buildable on your development laptop or workstation.</li>
<li>Implement basic security.</li>
<li>If relevant, have builds run in CI or your build system, so other people can use it.</li>
<li>Make the images easier to identify and debug.</li>
<li>Improve operational correctness.</li>
<li>Make the builds reproducible.</li>
<li>Speed up the build time.</li>
<li>Make the image smaller.</li>
</ol>
<blockquote>
<p><strong>Important:</strong> This chapter doesn’t cover all the best practices. You should also skim the guide and read the other best practices, to learn about other ways to enhance your build.</p>
</blockquote>
<h2 id="step-1-it-works">Step 1: It works</h2>
<p>The first step is just getting something working, so you have something you can improve. That means:</p>
<ol type="1">
<li>Writing your initial <code>Dockerfile</code>.</li>
<li>Writing the script that will run <code>docker image build</code>; for now it might be quite simple, but it’s likely to grow over time.</li>
</ol>
<p>I suggest starting with the following best practices:</p>
<ul>
<li>Choose a stable base image and tag (<a href="#base">ref</a>), which is not Alpine Linux (<a href="#no-alpine">ref</a>). Since you’ll need to choose a base image anyway, you may as well start with a good one.</li>
<li>For network servers, listen on <code>0.0.0.0</code> (<a href="#networkbind">ref</a>). Your image isn’t working if you can’t connect to it.</li>
<li>Write logs to <code>stdout</code> (<a href="#stdout-logs">ref</a>), so you can see what’s going when you run the container.</li>
<li>If you’re writing any shell scripts, make sure they’re not broken (<a href="#bash">ref</a>). In theory you can wait to do this later, but my experience is that if you don’t do this from the start, it can be difficult to add the necessary checks later on.</li>
</ul>
<p>If you’re installing system packages using <code>apt-get</code>, you’ll want to make sure <code>apt-get</code> never runs in interactive mode (<a href="#deb-interactive">ref</a>).</p>
<p>See also the best practices for Conda (<a href="#conda">ref</a>) and best practices for Poetry (<a href="#poetry">ref</a>) and Pipenv (<a href="#pipenv">ref</a>) if you’re using those tools.</p>
<h3 class="unnumbered" id="partial-example">Partial example</h3>
<p>At this point the <code>Dockerfile</code> for a simple application might look like this:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;python&quot;</span>, <span class="st">&quot;server.py&quot;</span>]</span></code></pre></div>
<p>And <code>build.sh</code> will look like this:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a><span class="ex">docker</span> image build -t yourimage .</span></code></pre></div>
<h2 id="step-2-basic-security">Step 2: Basic security</h2>
<p>Now that you have something working, the next step is to make your image sufficiently secure to run somewhere public. If it’s not secure, you can’t run it in production; if you can’t run it, what’s the point?</p>
<ul>
<li>Don’t listen on ports &lt; 1024 (<a href="#port-1024">ref</a>).</li>
<li>Don’t run as root (<a href="#no-root">ref</a>).</li>
<li>Run your container with no capabilities (<a href="#no-capabilities">ref</a>).</li>
<li>Update system packages in your <code>Dockerfile</code> (<a href="#update-system-packages">ref</a>).</li>
<li>Set up the technical and organizational processes you need to apply security fixes when they come out (<a href="#apply-security-fixes">ref</a>).</li>
<li>Don’t leak runtime secrets (<a href="#runtime-secrets">ref</a>) or build secrets (<a href="#builds-secrets">ref</a>).</li>
</ul>
<p>In some cases you might need to apply other best practices:</p>
<ul>
<li>If you’re using build secrets, make sure you’re not leaking them (<a href="#build-secrets">ref</a>), and likewise for runtime secrets (<a href="#runtime-secrets">ref</a>).</li>
<li>If you have any files you don’t want to be in the image for security reasons, make sure they’re not leaked (<a href="#secret-files">ref</a>).</li>
</ul>
<h3 class="unnumbered" id="partial-example-1">Partial example</h3>
<p>The <code>Dockerfile</code> might now look like this:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a><span class="co"># Install security updates:</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get -y upgrade</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a><span class="co"># Run as non-root user:</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a><span class="kw">RUN</span> useradd --create-home appuser</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true"></a><span class="kw">USER</span> appuser</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;python&quot;</span>, <span class="st">&quot;server.py&quot;</span>]</span></code></pre></div>
<h2 id="step-3-running-in-ci">Step 3: Running in CI</h2>
<p>Now that you have a working image with basic security, usually the next step is to build the images automatically in your CI or build system. This will allow other people on your team to get images built automatically, and reduce human error caused by manual builds.</p>
<p>You’ll typically want your build system to build the image and push it to your chosen image registry—perhaps on every commit, perhaps on pull requests, depending on your particular development workflow. You might also start thinking about automatic deploys at this point, depending how your production environment runs.</p>
<p>As you’re doing so, follow these best practices:</p>
<ul>
<li>Tag images based on the version control branch (<a href="#tag-branch">ref</a>).</li>
<li>Don’t rely on the <code>latest</code> tag (<a href="#latest-tag">ref</a>).</li>
<li>Set up an automatic rebuild-and-redeploy once a week so you get security updates to the image’s system packages (<a href="#weekly-rebuild">ref</a>).</li>
<li>Run security scanners on your code (<a href="#security-scanners">ref</a>).</li>
</ul>
<p>You can put these off until you’re working on faster builds, or do them here:</p>
<ul>
<li>For faster builds, warm up the build cache (<a href="#pull-in-ci">ref</a>).</li>
<li>Warm up the build cache for per-branch builds (<a href="#pull-in-ci-2">ref</a>).</li>
</ul>
<h3 class="unnumbered" id="partial-example-2">Partial example</h3>
<p>Your build script will now look something like this:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a><span class="va">IMAGE_NAME=</span>registry.example.com/yourorg/yourserver</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a><span class="va">GIT_BRANCH=$(</span><span class="fu">git</span> rev-parse --abbrev-ref HEAD<span class="va">)</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a><span class="va">GIT_COMMIT=$(</span><span class="fu">git</span> rev-parse --short HEAD<span class="va">)</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a><span class="co"># Pull previous version, and use with --cache-now</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true"></a><span class="co"># for build caching:</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true"></a><span class="ex">docker</span> pull <span class="va">$IMAGE_NAME</span>:<span class="va">$GIT_BRANCH</span> <span class="kw">||</span> <span class="fu">true</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true"></a><span class="co"># Use branch+commit for tagging:</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true"></a><span class="ex">docker</span> build -t <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_BRANCH</span><span class="st">&quot;</span> <span class="kw">\</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true"></a>             <span class="ex">-t</span> <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_COMMIT</span><span class="st">&quot;</span> <span class="kw">\</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true"></a>             <span class="ex">--build-arg</span> BUILDKIT_INLINE_CACHE=1 <span class="kw">\</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true"></a>             <span class="ex">--cache-from</span>=<span class="va">$IMAGE_NAME</span>:<span class="va">$GIT_BRANCH</span> .</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true"></a><span class="co"># Security scanners:</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true"></a><span class="ex">trivy</span> image --ignore-unfixed --exit-code 1 <span class="kw">\</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true"></a>    <span class="va">$IMAGE_NAME</span>:<span class="va">$GIT_BRANCH</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true"></a><span class="co"># Push to the registry:</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true"></a><span class="ex">docker</span> push <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_BRANCH</span><span class="st">&quot;</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true"></a><span class="ex">docker</span> push <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_COMMIT</span><span class="st">&quot;</span></span></code></pre></div>
<p>You’ll also need additional code to ensure a complete rebuild (<code>docker build --pull --no-cache</code>) once a week.</p>
<h2 id="step-4-easier-to-debug">Step 4: Easier to debug</h2>
<p>Now that your image is building automatically, you will start accumulating many more images. Now is the time to make images identifiable and easier to debug.</p>
<ul>
<li>Prepare for C crashes (<a href="#faulthandler">ref</a>). It’s one extra line in your <code>Dockerfile</code> that can save hours or even days of debugging later on.</li>
<li>Record the build’s version control revision and branch in the image itself (<a href="#identifiable">ref</a>).</li>
<li>Add a smoke test to your CI build (<a href="#smoke-test">ref</a>).</li>
</ul>
<p>You might also want to:</p>
<ul>
<li>Pre-install useful tools (<a href="#useful-tools">ref</a>).</li>
</ul>
<h3 class="unnumbered" id="partial-example-3">Partial example</h3>
<p>Your <code>Dockerfile</code> will add the following line:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a><span class="kw">ENV</span> PYTHONFAULTHANDLER=1</span></code></pre></div>
<p>And the build script’s <code>docker build</code> line will look like this:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a><span class="ex">docker</span> build -t <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_BRANCH</span><span class="st">&quot;</span> <span class="kw">\</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a>             <span class="ex">-t</span> <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_COMMIT</span><span class="st">&quot;</span> <span class="kw">\</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a>             <span class="ex">--label</span> git-commit=<span class="va">$GIT_COMMIT</span> <span class="kw">\</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a>             <span class="ex">--label</span> git-branch=<span class="va">$GIT_BRANCH</span> <span class="kw">\</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true"></a>             <span class="ex">--build-arg</span> BUILDKIT_INLINE_CACHE=1 <span class="kw">\</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true"></a>             <span class="ex">--cache-from</span>=<span class="va">$IMAGE_NAME</span>:<span class="va">$GIT_BRANCH</span> .</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true"></a><span class="ex">python</span> smoketest.py <span class="va">$IMAGE_NAME</span>:<span class="va">$GIT_BRANCH</span></span></code></pre></div>
<h2 id="step-5-additional-operational-correctness">Step 5: Additional operational correctness</h2>
<p>Next, you should make your images behave correctly.</p>
<ul>
<li>Make sure your image shuts down correctly (<a href="#shutdown">ref</a>).</li>
<li>Make sure your image can handle zombie processes correctly (<a href="#init">ref</a>).</li>
<li>If it’s a long-running process, implement health checks (<a href="#health-checks">ref</a>).</li>
<li>If it’s a server, make sure the server can handle health checks and slow queries at the same time (<a href="#slow-queries">ref</a>).</li>
<li>Pre-compile bytecode for faster startup (<a href="#bytecode">ref</a>).</li>
</ul>
<p>You may also want some application-specific and deployment environment configuration:</p>
<ul>
<li>Gunicorn requires certain options (<a href="#gunicorn">ref</a>).</li>
<li>uWSGI requires certain options (<a href="#uwsgi">ref</a>).</li>
<li>Heroku and Google Cloud Run require listening on a configurable port (<a href="#heroku">ref</a>).</li>
</ul>
<h3 class="unnumbered" id="partial-example-4">Partial example</h3>
<p>Your <code>Dockerfile</code> might now look like this:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get -y upgrade</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a><span class="co"># Install tini:</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true"></a><span class="kw">RUN</span> export DEBIAN_FRONTEND=noninteractive &amp;&amp; \</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true"></a>    apt-get install -y tini</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true"></a><span class="kw">RUN</span> useradd --create-home appuser</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true"></a><span class="kw">USER</span> appuser</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true"></a><span class="kw">ENV</span> PYTHONFAULTHANDLER=1</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true"></a><span class="co"># Use tini as an init process:</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;tini&quot;</span>, <span class="st">&quot;--&quot;</span>, <span class="st">&quot;python&quot;</span>, <span class="st">&quot;server.py&quot;</span>]</span></code></pre></div>
<h2 id="step-6-reproducible-builds">Step 6: Reproducible builds</h2>
<p>In the first week or so of packaging and development, it’s unlikely that any major changes will happen to your Python dependencies. As time goes on, the software you depend is more and more likely to change. And that can break your build, or break your application.</p>
<p>So next you should ensure your builds are reproducible, always installing the software versions you specifically asked for.</p>
<ul>
<li>Pin your Python dependencies (<a href="#pin-python">ref</a>).</li>
<li>Set up the technical and organizational processes to update all pinned dependencies once a month (<a href="#update-dependencies">ref</a>).</li>
</ul>
<p>You might also want to:</p>
<ul>
<li>Pin your system package dependencies (<a href="#pin-system">ref</a>).</li>
<li>Create a custom base image (<a href="#custom-base-image">ref</a>).</li>
</ul>
<h2 id="step-7-faster-builds">Step 7: Faster builds</h2>
<p>Now that you have good images, it’s time to look at optimizations. Your time is expensive, so it’s worth spending some effort to get faster builds, by optimizing Docker’s build caching.</p>
<p>If this is the second or third time you’re packaging an application, you might have done these automatically earlier on, but if not:</p>
<ul>
<li><code>COPY</code> in files only when needed (<a href="#copy-late">ref</a>).</li>
<li>Use <code>ARG</code> only when needed (<a href="#arg-late">ref</a>).</li>
<li>Install dependencies separately from your code (<a href="#install-dependencies-first">ref</a>).</li>
</ul>
<h3 class="unnumbered" id="partial-example-5">Partial example</h3>
<div class="sourceCode" id="cb8"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get -y upgrade</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a><span class="kw">RUN</span> export DEBIAN_FRONTEND=noninteractive &amp;&amp; \</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true"></a>    apt-get install -y tini</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true"></a><span class="co"># Only copy in requirements.txt for now:</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true"></a><span class="kw">RUN</span> useradd --create-home appuser</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true"></a><span class="kw">USER</span> appuser</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true"></a><span class="co"># Copy in the rest of the files:</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true"></a><span class="kw">ENV</span> PYTHONFAULTHANDLER=1</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;tini&quot;</span>, <span class="st">&quot;--&quot;</span>, <span class="st">&quot;python&quot;</span>, <span class="st">&quot;server.py&quot;</span>]</span></code></pre></div>
<h2 id="step-8-smaller-images">Step 8: Smaller images</h2>
<p>Finally, your images might be quite large at this point, so it’s good to make them smaller. This will save download time, as well as bandwidth and disk space.</p>
<ul>
<li>Keep temporary files from ending up in a layer (<a href="#temporary-files">ref</a>).</li>
<li>Add files to <code>.dockerignore</code> (<a href="#dockerignore">ref</a>).</li>
<li>Add <code>.git</code> to <code>.dockerignore</code>, or consider alternatives when you can’t (<a href="#git-dockerignore">ref</a>)</li>
<li>Avoid extra <code>chown</code>s (<a href="#chown">ref</a>).</li>
<li>Minimize system package installation (<a href="#system-packages-clean">ref</a>).</li>
<li>Reduce disk usage from <code>pip</code> installs (<a href="#smaller-pip">ref</a>).</li>
</ul>
<p>You might find that you can’t have both small images and fast builds. Typically this happens when you need to install a compiler toolchain: caching enables fast builds, but also makes your images larger. In this situation you may want to consider multi-stage builds (<a href="#multi-stage">ref</a>).</p>
<h3 class="unnumbered" id="partial-example-6">Partial example</h3>
<p>Your <code>Dockerfile</code> might now look like this:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true"></a><span class="co"># Clean up after installing packages:</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true"></a><span class="kw">RUN</span> export DEBIAN_FRONTEND=noninteractive &amp;&amp; \</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true"></a>    apt-get update &amp;&amp; \</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true"></a>    apt-get -y upgrade &amp;&amp; \</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true"></a>    apt-get install -y --no-install-recommends tini &amp;&amp; \</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true"></a>    apt-get -y clean &amp;&amp; \</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true"></a>    rm -rf /var/lib/apt/lists/*</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true"></a><span class="co"># Don&#39;t cache pip-downloaded packages:</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true"></a><span class="kw">RUN</span> pip install --no-cache-dir -r requirements.txt</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true"></a><span class="kw">RUN</span> useradd --create-home appuser</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true"></a><span class="kw">USER</span> appuser</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true"></a><span class="kw">ENV</span> PYTHONFAULTHANDLER=1</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;tini&quot;</span>, <span class="st">&quot;--&quot;</span>, <span class="st">&quot;python&quot;</span>, <span class="st">&quot;server.py&quot;</span>]</span></code></pre></div>
<h1 id="docker-versions-and-buildkit">Docker versions and BuildKit</h1>
<p>Before moving on to the details of the best practices, it’s worth understanding the available versions of Docker, and what they support.</p>
<h2 id="docker-20.10">Docker 20.10</h2>
<p>As of September 2022, you will mostly encounter Docker 20.10 in the wild, unless you’re using an older Linux distribution. If you’re using Docker Desktop on macOS and Windows you will end up getting updated to Docker 20.10 as part of the update process.</p>
<p>Docker 20.10 has a number of new features; I will mention them inline where relevant.</p>
<p>If you are using older versions, I recommend upgrading: you’re missing years’ worth of bug fixes and enhancements.</p>
<h2 id="buildkit">BuildKit</h2>
<p>BuildKit is a re-implementation of Docker’s image building system, included in both Docker 19.03 and 20.10. It includes performance enhancements, like parallel builds where possible, and new features like build secrets, SSH agent forwarding from the host, and additional caching features.</p>
<p>To enable it:</p>
<ul>
<li>You can set the environment variable <code>DOCKER_BUILDKIT</code> to <code>1</code>, e.g. <code>export DOCKER_BUILDKIT=1</code>.</li>
<li>On recent versions of Docker Desktop on macOS and Windows there should be a setting in the Preferences UI; on new installs it will be enabled by default.</li>
</ul>
<h3 id="getting-complete-output-with-buildkit">Getting complete output with BuildKit</h3>
<p>BuildKit changes the way build progress is output. To make sure you see the output of <code>RUN</code> commands, you can run with the <code>--progress=plain</code> command-line argument.</p>
<pre><code>$ docker image build --progress=plain .</code></pre>
<h3 id="enabling-buildkit-features-in-your-dockerfile">Enabling BuildKit features in your Dockerfile</h3>
<p>With the release of Docker 20.10, BuildKit has now stabilized, which is why it is enabled by default on new macOS and Windows installs.</p>
<p>Among other features, BuildKit allows configuring the builder a per-<code>Dockerfile</code> basis. On Docker 20.10 it will use BuildKit v1.3 syntax by default when BuildKit is enabled, but on Docker 19.03 you need to set this explicitly in your <code>Dockerfile</code>. It’s worth doing explicitly in any case, so you can get newer versions of the syntax, the latest being v1.4:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true"></a><span class="co"># syntax = docker/dockerfile:1.4</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true"></a><span class="co"># ... rest of Dockerfile goes here</span></span></code></pre></div>
<p>On Docker 20.10 this isn’t strictly necessary, but it is still worthwhile: you’ll automatically get the latest bugfix version downloaded (it’s a Docker image!), even if it’s not packaged in your particular release of Docker 20.10. If you’re using BuildKit, then, you should just add that line at the top of all your <code>Dockerfile</code>s.</p>
<p>BuildKit mostly works pretty well on Docker 19.03, so you can use it even if you still haven’t upgraded to 20.10.</p>
<p>Again, I will be covering BuildKit features inline where relevant.</p>
<h3 id="enabling-buildkit-with-docker-compose">Enabling BuildKit with Docker Compose</h3>
<p>Docker Compose doesn’t work out of the box with BuildKit. You can enable support for BuildKit by setting an additional environment variable beyond <code>DOCKER_BUILDKIT</code>:</p>
<pre class="shell-session"><code>$ export COMPOSE_DOCKER_CLI_BUILD=1</code></pre>
<p>Unfortunately this method of using Docker results in somewhat worse error messages when builds fail. Not all BuildKit features are supported, see the best practice below on <a href="#compose-secrets">build secrets with Compose</a>.</p>
<h3 id="ensuring-caching-works-correctly-with-buildkit">Ensuring caching works correctly with BuildKit</h3>
<p>BuildKit has a much more sophisticated caching system; you can export the cache to the filesystem, and store it separately from images. In order for caching to work the way it previously worked with Docker when using <code>--cache-from</code>, you will need to add <code>--build-arg BUILDKIT_INLINE_CACHE=1</code> to your build script. See the best practice on warming the cache for details (<a href="#pull-in-ci">ref</a>).</p>
<h2 id="podman">Podman</h2>
<p>On RedHat operating systems, an alternative implementation of Docker called Podman is installed. Podman is supposed to be completely compatible with Docker on the CLI side and to some extent on the API side as well, allowing support for tools like Docker Compose. Over time Podman has also added support for BuildKit features like build secrets and mount caches; make sure you’re using the latest release for maximum functionality.</p>
<p>Alternatively, you can always install a normal Docker on these Linux distributions.</p>
<h3 id="references">References</h3>
<ul>
<li><a href="https://hub.docker.com/r/docker/dockerfile/"><code>docker/dockerfile</code> reference</a> (hub.docker.com)</li>
<li><a href="https://docs.docker.com/develop/develop-images/build_enhancements/">BuildKit features overview (outdated)</a> (docs.docker.com)</li>
<li><a href="https://podman.io/">Podman</a> (podman.io)</li>
<li><a href="https://github.com/moby/buildkit">BuildKit repository</a> (github.com)</li>
<li><a href="https://www.docker.com/blog/faster-builds-in-compose-thanks-to-buildkit-support/">BuildKit in Compose</a> (docker.com)</li>
</ul>
<h2 id="the-problem-with-arm-macs">The problem with ARM Macs</h2>
<p>Newer macOS machines use an ARM-based CPU (“Apple Silicon”), with specific models being M1 and M2. These CPUs are a fundamentally different architecture than the x86-64 (aka Intel, aka amd64) architecture used on most Windows and Linux PCs, and most cloud virtual machines and servers. There are ARM servers available, for example AWS Graviton VMs, but they are still not the default.</p>
<p>Docker images are built in architecture-specific versions, so you can download a separate <code>python:3.10</code> image for <code>linux/amd64</code> (i.e. x86-64) and another for <code>linux/arm64/v8</code> (i.e. ARM). Careful, <code>amd64</code> and <code>arm64</code> are visually similar and easy to confuse!</p>
<p>With Docker on your Mac, there are two approaches to using Docker images:</p>
<ul>
<li>Install the fast, native ARM images. The problem is that many Python packages don’t have wheels compiled for ARM (<code>aarch64</code> wheels, i.e. ARM for Linux) uploaded to PyPI, so you might have to compile packages from source, which means very slow builds.</li>
<li>Use the x86-64 Docker images, with CPU emulation. The emulation is slow, so images will run slowly, but you have access to all the normal x86-64 wheels. What’s more, this is the kind of image you’d be deploying, since most servers are on x86-64 CPUs.</li>
</ul>
<p>You can force using x86-64 images on the command-line:</p>
<pre class="shell-session"><code>macos:% docker build --platform linux/amd64 -t myimage .
...
macos:% docker run --platform linux/amd64 myimage</code></pre>
<p>Or with an environment variable:</p>
<pre class="shell-session"><code>macos:% export DOCKER_DEFAULT_PLATFORM=linux/amd64
macos:% docker build -t myimage .
...
macos:% docker run myimage</code></pre>
<p>Or you can set this in the <code>Dockerfile</code>:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true"></a><span class="kw">FROM</span> --platform=linux/amd64 python:3.9-slim</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true"></a><span class="kw">RUN</span> pip install murmurhash==1.0.6</span></code></pre></div>
<p>It is possible that the speed issues with x86-64 will be solved in the future, as Apple’s Rosetta CPU emulation tool will start supporting Linux virtual machines, something Docker Desktop may be able to take advantage of.</p>
<p>For more details and suggestions, see the linked article below.</p>
<h3 id="references-1">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/docker-build-problems-mac/">Why new Macs break your Docker build</a> (pythonspeed.com)</li>
<li><a href="https://docs.docker.com/desktop/mac/apple-silicon/">Docker Desktop for Apple silicon</a> (docs.docker.com)</li>
</ul>
<h1 id="best-practices-security">Best practices: Security</h1>
<h2 id="no-root">Don’t run as root</h2>
<p>Running your Docker image as root exposes you to significant security risks: it makes it much easier for an attacker to get root on the host. Better, then, to start your container as a non-root user:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true"></a><span class="kw">RUN</span> useradd --create-home appuser</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true"></a><span class="kw">WORKDIR</span> /home/appuser</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true"></a><span class="kw">USER</span> appuser</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;yourprogram&quot;</span>]</span></code></pre></div>
<p>Note that <code>USER</code> only affects commands after it is used, so you can still run commands as root beforehand:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true"></a><span class="kw">RUN</span> useradd --create-home appuser</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true"></a><span class="kw">WORKDIR</span> /home/appuser</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true"></a><span class="co"># This runs as root:</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true"></a><span class="kw">RUN</span> chmod 777 /var/log</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true"></a><span class="kw">USER</span> appuser</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true"></a><span class="co"># This runs as appuser:</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true"></a><span class="kw">RUN</span> pip install yourpackage</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true"></a><span class="co"># And this runs as appuser:</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;python&quot;</span>, <span class="st">&quot;-m&quot;</span>, <span class="st">&quot;yourcode&quot;</span>]</span></code></pre></div>
<p>You can use tools like <code>gosu</code> to change away from root after startup, but that will prevent you from running the container with reduced capabilities (see below), which is another useful security measure. Better then to use <code>USER</code>.</p>
<h3 id="references-2">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/root-capabilities-docker-security/">Less capabilities, more security: minimizing privilege escalation in Docker</a> (pythonspeed.com)</li>
<li><a href="https://docs.docker.com/engine/reference/builder/#user"><code>Dockerfile</code> <code>USER</code> command</a> (docs.docker.com)</li>
<li><a href="https://www.man7.org/linux/man-pages/man8/useradd.8.html"><code>useradd(8)</code> man page</a> (www.man7.org)</li>
</ul>
<h2 id="port-1024">Don’t listen on ports &lt; 1024</h2>
<p>In order to listen on TCP or UDP ports less than 1024 on Linux, you need to either run as root or have the relevant security capability (see below). Since you don’t want to run as root, nor grant your container unnecessary capabilities, you should always listen on port 1024 or higher.</p>
<p>But what if you do need to listen on a low port? For example, an HTTPS server needs to listen on port 443 if you want a standard <code>https://</code> URL to work.</p>
<p>Remember that when you run your container you are doing port-forwarding to expose the service, and the external port on the host doesn’t have to match the port inside the container. So you can do:</p>
<pre><code>$ docker run -p 443:8443 yourcontainer</code></pre>
<p>And now port 443 on the host maps to port 8443 in the container.</p>
<p>Pretty much every system that can run a container has similar options. There is therefore no reason to listen on ports &lt; 1024.</p>
<h2 id="no-capabilities">Run your container with no capabilities</h2>
<p>Linux “capabilities” allow you to grant a subset of root’s power to a process. A process may have some capabilities currently in effect, and some capabilities it can inherit when it executes an executable with the ability to grant capabilities.</p>
<p>By default when running as non-root user in Docker, the process has no effective capabilities, but it can inherit quite a few when it run an executable. For example, here you can see that running <code>/usr/bin/ping</code> granted the resulting process the ability to turn on <code>cap_net_raw</code> capability:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true"></a>$ <span class="ex">docker</span> run --user=1000 -it centos</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true"></a><span class="ex">bash-4.4</span>$ getcap /usr/bin/ping</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true"></a><span class="ex">/usr/bin/ping</span> = cap_net_admin,cap_net_raw+p</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true"></a><span class="ex">bash-4.4</span>$ ping example.com <span class="op">&gt;</span> /dev/null <span class="kw">&amp;</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true"></a>[<span class="ex">1</span>] 13</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true"></a><span class="ex">bash-4.4</span>$ getpcaps 13</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true"></a><span class="ex">Capabilities</span> for <span class="kw">`</span><span class="ex">13</span><span class="st">&#39;: = cap_net_raw+p</span></span></code></pre></div>
<p>If <code>ping</code> has a security vulnerability that allows injecting code into it, an attacker now has access to escalated privileges. You can solve this by running the container with no capabilities:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true"></a>$ <span class="ex">docker</span> run --user=1000 --cap-drop=ALL -it centos</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true"></a><span class="ex">bash-4.4</span>$ ping example.com</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true"></a><span class="ex">ping</span>: socket: Operation not permitted</span></code></pre></div>
<p>Kubernetes has similar options.</p>
<p>Technically this best practice is about running your container, not about packaging. But as mentioned in the previous two best practices it does have an impact on how you should package your application.</p>
<h3 id="references-3">References</h3>
<ul>
<li><a href="https://www.man7.org/linux/man-pages/man7/capabilities.7.html"><code>capabilities(7)</code> man page</a> (www.man7.org)</li>
<li><a href="https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities"><code>docker run</code> capabilities options</a> (docs.docker.com)</li>
<li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/">Kubernetes Pod security context</a> (kubernetes.io)</li>
</ul>
<h2 id="update-system-packages">Update system packages</h2>
<p>The system packages in the base image you are using may or may not be up-to-date, which means they might not include the latest security updates. You should therefore update them at the start of your build.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get -y upgrade</span></code></pre></div>
<p>There are more fully fleshed-out scripts in <a href="#system-packages-clean">a later handbook item</a>.</p>
<h2 id="weekly-rebuild">∞ Rebuild without caching and redeploy at least weekly ∞</h2>
<p>Even if your code hasn’t changed, you still need to rebuild your image and redeploy it on a regular basis.</p>
<ol type="1">
<li>The system packages you depend on will have new releases, due to security flaws and other bugs.</li>
<li>The Python base image may also have a new point release with security fixes.</li>
</ol>
<p>For example, if your image uses <code>nginx</code> and <code>nginx</code> has a remote execution attack, you don’t want to wait until a new release of your code to deploy a fixed <code>nginx</code>.</p>
<p>You should therefore rebuild your images once a week, and then redeploy them.</p>
<p>You also need to make sure these rebuilds actually get the updates. Remember that Docker build caching will skip updating a layer if the command hasn’t changed. That means that if you have a cached version, <code>apt-get upgrade</code> won’t run even if there are new packages!</p>
<p>You should therefore rebuild with <code>--no-cache</code>, so all layers are rebuilt, and with <code>--pull</code> so that you’re using the latest base image:</p>
<pre><code>$ docker build -t example.com/myorg/myimage --no-cache --pull .
$ docker push example.com/myorg/myimage</code></pre>
<h3 id="references-4">References</h3>
<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/build/"><code>docker build</code> reference</a> (docs.docker.com)</li>
<li><a href="https://pythonspeed.com/articles/docker-cache-insecure-images/">Avoiding insecure images from Docker build caching</a> (pythonspeed.com)</li>
</ul>
<h2 id="apply-security-fixes">∞ Apply security fixes when they come out ∞</h2>
<p>Over time, software packages you depend on will get security fixes as well as fixes to critical bugs. Insofar as you’ve pinned your packages, you will need to apply these fixes yourself. And you want to get notified when new packages are released with these fixes, so that you know an update is needed.</p>
<p>GitHub has scanning functionality built-in for Pip, Pipenv, and Poetry; see the documentation linked in references. There are also other services like <a href="https://requires.io/">requires.io</a>, <a href="https://pyup.io">PyUp</a>, and more.</p>
<p>These tools will notify you of Python vulnerabilities and updates, but will not track pinned system packages; you’ll need to track those yourself. If you’re using a Debian-based base image, for example, you can track the Debian security releases.</p>
<p>Once you’ve realized you have a security vulnerability, either via a notification or via a security scanner (see the next best practice), you will need to:</p>
<ol type="1">
<li>Update your package dependencies with the fixed version, if you’re pinning versions.</li>
<li>Rebuild the image.</li>
<li>Redeploy the image anywhere it’s currently running.</li>
</ol>
<h3 id="references-5">References</h3>
<ul>
<li><a href="https://www.debian.org/security/">Debian security information</a> (debian.org)</li>
<li><a href="https://usn.ubuntu.com/">Ubuntu security notices</a> (usn.ubuntu.com)</li>
<li><a href="https://access.redhat.com/security/security-updates/#/security-advisories">RHEL security advisories</a> (access.redhat.com)</li>
<li><a href="https://docs.github.com/en/code-security/supply-chain-security/keeping-your-dependencies-updated-automatically">GitHub dependency auto-updates</a> (github.com)</li>
<li><a href="https://docs.github.com/en/code-security/supply-chain-security/managing-vulnerabilities-in-your-projects-dependencies">GitHub dependency security vulnerability alerts</a>(github.com)</li>
</ul>
<h2 id="security-scanners">Run security scanners</h2>
<p>In your CI system you can run security scanners to scan:</p>
<ol type="1">
<li>Your code for potential security bugs.</li>
<li>Your dependencies for known vulnerabilities.</li>
<li>System packages and packages in other languages for known vulnerabilities.</li>
</ol>
<h3 id="potential-vulnerabilities-in-your-python-code">Potential vulnerabilities in your Python code</h3>
<p><code>bandit</code> is a tool for finding vulnerabilities in your Python code; it will search for things like SQL injection attacks, use of pickle, and many more. You might want to run it via <code>flake8-bandit</code>, so you get the benefit of <code>flake8</code>’s generic skipping and configuration mechanism.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true"></a>$ <span class="ex">python3</span> -m venv /tmp/security</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true"></a>$ <span class="bu">.</span> <span class="ex">/tmp/security/bin/activate</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true"></a>$ <span class="ex">pip</span> install bandit</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true"></a>$ <span class="ex">bandit</span> example.py</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true"></a><span class="ex">...</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true"></a><span class="op">&gt;&gt;</span> <span class="ex">Issue</span>: [B403:blacklist] Consider possible security implications associated with pickle module.</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true"></a><span class="ex">...</span></span></code></pre></div>
<h3 id="known-vulnerabilities-in-python-dependencies-system-packages-and-other-languages">Known vulnerabilities in Python dependencies, system packages, and other languages</h3>
<p><a href="https://github.com/aquasecurity/trivy">Trivy</a> is a command-line tool that lets you scan a Docker image, the filesystem, or a remote repository, for many kinds of security vulnerabilities, both system packages (RHEL, Debian, Ubuntu, and more) and programming language-specific packages. <code>trivy</code> also supports checking <code>requirements.txt</code>, Poetry, and Pipenv dependency files.</p>
<p>Trivy reports <em>known</em> vulnerabilities that someone already reported. That’s different than Bandit, which looks for <em>possible</em> vulnerabilities–you could in theory also run Bandit against dependencies and find some real issues that no one knew existed.</p>
<blockquote>
<p><strong>Note:</strong> Make sure you’re using <code>trivy</code> v0.23 or later; older versions had some restrictions on commercial usage.</p>
<p>Many hosted image registries will also do scans for you. You should always check what a particular scanner supports; not all of them will necessarily check Python dependencies.</p>
</blockquote>
<p>By default <code>trivy</code> will show vulnerabilities that don’t have any fixes available, including many vulnerabilities that will <em>never</em> have any fixes available. You may wish to ignore these (if there’s no fix, what can you do?) by using the <code>--ignore-unfixed</code> option. Note that this is only supported for some operating systems.</p>
<p>Additionally, by default <code>trivy</code> won’t set a non-zero exit code when vulnerabilities are found. If you’re using Trivy as part of CI or other automated script, you’ll want to use the <code>--exit-code</code> option to make sure found vulnerabilities are noted as a failure, e.g. <code>--exit-code 1</code>.</p>
<p>To scan the image <code>yourorg/yourimage</code>, you can do:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true"></a>$ <span class="ex">trivy</span> image --ignore-unfixed --exit-code 1 yourorg/yourimage</span></code></pre></div>
<p>To scan a local directory, you can do:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true"></a>$ <span class="ex">trivy</span> fs --ignore-unfixed --exit-code 1 ./path/to/code/</span></code></pre></div>
<p>The Trivy documentation explains how to use it with many CI systems (GitHub Actions, Circle CI, GitLab CI, and more); see the “Advanced” section of the docs.</p>
<p>An alternative Trivy is the Grype security scanner.</p>
<h3 id="secrets">Secrets</h3>
<p>Trivy will also scan for leaked secrets in your image, but it’s not as robust as one might like. As of v0.32 it seems to mostly focus on specific kinds of known secrets like AWS keys, so it will miss passwords or secrets that don’t fit the limited patterns it knows about.</p>
<p>A more robust tool is GitGuardian. You can get a free account from the service that gives a pretty decent number of free scans. You’ll need to generate an API token through their dashboard. Then:</p>
<pre><code>$ export GITGUARDIAN_API_KEY=the-token-you-got-from-dashboard
$ python3 -m venv /tmp/venv
$ /tmp/venv/bin/pip install ggshield
$ ggshield scan docker yourorg/your-image</code></pre>
<h3 id="references-6">References</h3>
<ul>
<li><a href="https://bandit.readthedocs.io">Bandit documentation</a> (bandit.readthedocs.io)</li>
<li><a href="https://pypi.org/project/flake8-bandit/">flake8-bandit</a> (pypi.org)</li>
<li><a href="https://aquasecurity.github.io/trivy/">Trivy documentation</a> (aquasecurity.github.io)</li>
<li><a href="https://github.com/anchore/grype">Grype security scanner</a> (github.com)</li>
<li><a href="https://www.gitguardian.com/docker-security">GitGuardian</a> (gitguardian.com)</li>
</ul>
<h2 id="secret-files">Don’t leak secret files</h2>
<p>Imagine you have the following files in your build directory:</p>
<pre><code>Dockerfile
app/
  __init__.py
  code.py
run.sh
id_rsa</code></pre>
<p>The <code>id_rsa</code> file is a private SSH key used to access a private repository–you do not want it to end up in the image. If it does, any attacker who gains access to the image will be to extract this secret file.</p>
<p>If you do the following:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true"></a><span class="kw">COPY</span> . .  <span class="co"># INSECURE</span></span></code></pre></div>
<p>Then by default <code>id_rsa</code> will get copied in to the image.</p>
<p>You can avoid this by explicitly copying in only the files you need:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true"></a><span class="kw">COPY</span> app/ run.sh ./</span></code></pre></div>
<p>You can also add <code>id_rsa</code> to <a href="#dockerignore"><code>.dockerignore</code></a> so it doesn’t get copied in.</p>
<p>Finally, you can avoid having secrets in the same directory as your Docker build context.</p>
<h2 id="runtime-secrets">Don’t leak runtime secrets</h2>
<p>Your Docker image may require a variety of secrets to run correctly. For example, your web application might require the password to its MySQL database. These are known as runtime secrets, and you should not store them in your image, since an attacker who gains access to the image will be able to read them.</p>
<p>There are a variety of runtime-specific mechanisms for passing secrets into a running container:</p>
<ul>
<li>Using environment variables passed in at runtime, using e.g. <code>docker run --env/--env-file</code>, Docker Compose <code>environment/env_file</code> keys, or the Kubernetes equivalents.</li>
<li>Mounting a volume or host directory with the secret.</li>
<li>Secret-specific mechanisms like Kubernetes secrets (which actually uses both mechanisms above).</li>
<li>In some cloud environments, you can give permissions to containers to talk to the cloud environment, e.g. IAM roles for ECS tasks on AWS.</li>
<li>Retrieving them from some sort of external key store like HashiCorp’s Vault.</li>
</ul>
<blockquote>
<p>Note that “volume” is used inconsistently in Docker. Sometimes it means “a mini-filesystem managed by Docker”, or if you’re using Kubernetes a “mini-filesystem managed by Kubernetes or a system it talks to.” Sometimes it is used more generically as the configuration option to mount either volumes in the previous sense or bind mount directories from the host system.</p>
<p>Either way, the key point is that the secret should not be in the image itself.</p>
</blockquote>
<h3 id="references-7">References</h3>
<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/run/#set-environment-variables--e---env---env-file">Setting Docker environment variables at runtime</a> (docs.docker.com)</li>
<li><a href="https://docs.docker.com/storage/bind-mounts/">Bind mounting</a> (docs.docker.com)</li>
<li><a href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes secrets</a> (kubernetes.io)</li>
<li><a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html">IAM in ECS</a> (docs.aws.amazon.com)</li>
<li><a href="https://www.vaultproject.io/">HashiCorp Vault</a> (vaultproject.io)</li>
</ul>
<h2 id="build-secrets">Don’t leak build secrets</h2>
<p>Sometimes during a build you need to download source code or packages using a secret: a password, or an SSH private key. This is not the same as a <em>runtime</em> secret. Rather, it’s a secret you will only need during the Docker image build, to download some build dependencies.</p>
<p>The obvious mechanism to pass secrets in is <code>docker build --build-arg</code>, but this is insecure: the secret will be embedded in the image, so anyone who has access to the image can see the secret by running <code>docker history</code>. You can also <code>COPY</code> in secrets, but then they will be leaked via the images.</p>
<p>To solve this you have a number of alternatives:</p>
<ol type="1">
<li>Use a short-term key or access token that will expire after a few minutes.</li>
<li>Pre-download the necessary packages or source code outside of the Docker build, then <code>COPY</code> the files in as normal. In this case you don’t need to pass the secret in to the Docker build at all.</li>
<li>Use the new BuildKit backend for Docker builds, which supports passing in secrets as well as SSH authentication-agent forwarding. Podman also support this feature.</li>
<li>Pass in the secrets over the network. There is no reason to use this method at this point.</li>
</ol>
<h3 id="a-short-term-expiring-access-token">A short term expiring access token</h3>
<p>Some package repositories support the creation of short term access tokens. If your access token expires after 5 minutes, it doesn’t matter if you leak it in your image so long as the push happens more than 5 minutes after token creation. You can then use build args or <code>COPY</code> to get the secret in.</p>
<h3 id="pre-download-necessary-files">Pre-download necessary files</h3>
<p>Here’s how this option would work if, for example, you need a private SSH key to download some code:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true"></a>$ <span class="bu">eval</span> <span class="va">$(</span><span class="fu">ssh-agent</span><span class="va">)</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true"></a>$ <span class="fu">ssh-add</span> ~/.ssh/id_rsa</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true"></a>$ <span class="fu">git</span> clone git@github.com:yourorg/yourprivatecode.git</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true"></a>$ <span class="ex">docker</span> build -t yourimage .</span></code></pre></div>
<p>And the <code>Dockerfile</code> would just need to copy in the code:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true"></a><span class="kw">COPY</span> yourprivatecode .</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true"></a><span class="co"># RUN the build, etc.</span></span></code></pre></div>
<h3 id="buildkit-secrets">BuildKit secrets</h3>
<p>Here’s how you would use BuildKit or Podman to pass in build secrets. Let’s say you have a file with a secret:</p>
<pre><code>$ cat secret-file
THIS IS SECRET</code></pre>
<p>First, configure your <code>Dockerfile</code> to use BuildKit, and add a flag to <code>RUN</code> telling it to expose a particular secret:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true"></a><span class="co"># syntax = docker/dockerfile:1.4</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true"></a><span class="kw">COPY</span> build-script.sh .</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true"></a><span class="kw">RUN</span> --mount=type=secret,id=mysecret ./build-script.sh</span></code></pre></div>
<p>The <code>build-script.sh</code> will be able to find the secret at <code>/run/secrets/mysecret</code>.</p>
<p>Then, to build your image with the secret set the appropriate environment variable and pass in the newly enabled command-line arguments:</p>
<pre><code>$ export DOCKER_BUILDKIT=1
$ docker build --secret id=mysecret,src=secret-file .</code></pre>
<p>Docker 20.10 adds the additional ability to load secrets from environment variables, not just files. For example, if you have an environment variable <code>MYSECRET</code>, you can access it like this:</p>
<pre><code>$ export MYSECRET=theverysecretpassword
$ export DOCKER_BUILDKIT=1
$ docker build --secret --secret id=mysecret,env=MYSECRET .</code></pre>
<p>If you’re OK with the secret ID being the same as the name as the environment variable, you can replace the last command with:</p>
<pre><code>$ docker build --secret --secret id=MYSECRET .</code></pre>
<p>Note that it will still be exposed inside the build as a file in <code>/run/secrets</code>, it is merely read from an environment variable on the host.</p>
<h3 id="references-8">References</h3>
<ul>
<li><a href="https://docs.docker.com/develop/develop-images/build_enhancements/">Docker BuildKit backend documentation</a> (docs.docker.com)</li>
<li><a href="https://pythonspeed.com/articles/docker-build-secrets/">Docker build secrets</a> (pythonspeed.com)</li>
</ul>
<h2 id="compose-secrets">Using BuildKit secrets from Docker Compose v1</h2>
<p>Docker Compose v1 does not support using BuildKit secrets, and most of the development is happening on v2. On the other hand, v2 is still a work progress, not well documented except via a reference, and not quite compatible. For v1 it is possible to use a workaround, however. For details on v2 see the next chapter.</p>
<p>The basic idea is to have code that supports either secrets file or environment variables (via build args). When using <code>docker build</code> to build the released image, you use the secure secrets file; when building locally in Docker Compose, you use the insecure build argument.</p>
<p>Let’s say you have a script <code>use_secret.sh</code> that wants to download a file using a password. You’d write it like this:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true"></a><span class="co"># Support both secrets file and an env variable:</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true"></a><span class="kw">if</span><span class="bu"> [</span> <span class="ot">-f</span> /run/secrets/thepassword<span class="bu"> ]</span>; <span class="kw">then</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true"></a>   <span class="bu">export</span> <span class="va">THEPASSWORD=$(</span><span class="fu">cat</span> /run/secrets/thepassword<span class="va">)</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true"></a><span class="kw">fi</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true"></a><span class="fu">wget</span> -o download.zip https://admin:<span class="va">$THEPASSWORD</span>@example.com/download.zip</span></code></pre></div>
<p>The <code>Dockerfile</code> would look like this:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true"></a><span class="co"># syntax = docker/dockerfile:1.4</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true"></a><span class="co"># Only use the build arg for local development:</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true"></a><span class="kw">ARG</span> THEPASSWORD</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true"></a><span class="kw">COPY</span> use_secret.sh .</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true"></a><span class="co"># Mount the secret to /run/secrets:</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true"></a><span class="kw">RUN</span> --mount=type=secret,id=thepassword ./use_secret.sh</span></code></pre></div>
<p>When you did a normal build, you would pass the secret in using a secure mechanism:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true"></a><span class="bu">export</span> <span class="va">DOCKER_BUILDKIT=</span>1</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true"></a><span class="ex">docker</span> build -t myimage <span class="kw">\</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true"></a>    <span class="ex">--secret</span> id=thepassword,src=mypassword.txt .</span></code></pre></div>
<p>Your Compose file in contrast would use build arguments:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true"></a><span class="fu">version</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;3.7&quot;</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true"></a><span class="fu">services</span><span class="kw">:</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true"></a><span class="at">  </span><span class="fu">yourapp</span><span class="kw">:</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true"></a><span class="at">    </span><span class="fu">build</span><span class="kw">:</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true"></a><span class="at">      </span><span class="fu">context</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;.&quot;</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true"></a><span class="at">      </span><span class="fu">args</span><span class="kw">:</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true"></a><span class="at">        </span><span class="fu">THEPASSWORD</span><span class="kw">:</span><span class="at"> </span><span class="st">&quot;$THEPASSWORD&quot;</span></span></code></pre></div>
<p>And to use it you set <code>$THEPASSWORD</code> and the environment variables needed to make Compose use BuildKit:</p>
<pre><code>$ export THEPASSWORD=$(cat mypassword.txt)
$ export DOCKER_BUILDKIT=1
$ export COMPOSE_DOCKER_CLI_BUILD=1
$ docker-compose up</code></pre>
<h3 id="references-9">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/build-secrets-docker-compose/">Build secrets in Docker Compose, the secure way</a> (pythonspeed.com)</li>
<li><a href="https://www.docker.com/blog/faster-builds-in-compose-thanks-to-buildkit-support/">BuildKit support in Docker Compose 1.25.1+</a> (docker.com)</li>
<li><a href="https://github.com/docker/compose/issues/6358">Issue #6358: Support for BuildKit secrets in Docker Compose</a> (github.com)</li>
</ul>
<h2 id="using-build-secrets-in-docker-compose-v2">Using build secrets in Docker Compose v2</h2>
<p>Newer versions of Compose v2 have basic, somewhat incompatible support for build secrets. If for example you have a file <code>mysecret.txt</code>, you can mount it at build time at <code>/run/secrets/mysecret</code> by doing:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true"></a><span class="fu">services</span><span class="kw">:</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true"></a><span class="at">  </span><span class="fu">yourservice</span><span class="kw">:</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true"></a><span class="at">    </span><span class="fu">build</span><span class="kw">:</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true"></a><span class="at">      </span><span class="fu">context</span><span class="kw">:</span><span class="at"> .</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true"></a><span class="at">      </span><span class="fu">secrets</span><span class="kw">:</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true"></a><span class="at">        </span><span class="kw">-</span><span class="at"> mysecret</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true"></a><span class="fu">secrets</span><span class="kw">:</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true"></a><span class="at">  </span><span class="fu">mysecret</span><span class="kw">:</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true"></a><span class="at">    </span><span class="fu">file</span><span class="kw">:</span><span class="at"> ./mysecret.txt</span></span></code></pre></div>
<p>Commands running in your Dockerfile can then access it at <code>/run/secrets/mysecret</code>.</p>
<p>At the moment there doesn’t appear to be support for environment variables.</p>
<h3 id="references-10">References</h3>
<ul>
<li><a href="https://docs.docker.com/compose/compose-file/build/#secrets">Build secrets in Compose v2</a> (docs.docker.com)</li>
</ul>
<h2 id="use-host-ssh-keys-with-buildkit-ssh-agent-forwarding">Use host SSH keys with BuildKit <code>ssh-agent</code> forwarding</h2>
<p>If you have an SSH private key on your host, perhaps password-protected, and you want to make it available to multiple processes without having to type that password each time, you can use <code>ssh-agent</code>.</p>
<pre><code>$ eval `ssh-agent`
$ ssh-add ~/.ssh/id_rsa
Password: ******</code></pre>
<p>Now, all future <code>ssh</code> calls will be able to use that private key without having to type in the password, since the agent has it cached in memory.</p>
<p>If you’re using BuildKit, you can give the Docker build access to the private SSH keys on the host by talking the <code>ssh-agent</code> running on the host, and without leaking them into the image.</p>
<p>Your <code>Dockerfile</code> will look like this:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true"></a><span class="co"># syntax = docker/dockerfile:1.4</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; \</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true"></a>    apt-get -y install --no-install-recommends openssh-client git</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true"></a><span class="kw">RUN</span> --mount=type=ssh git clone git@github.com:yourorg/private.git</span></code></pre></div>
<p>And then you’d build it like this:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true"></a><span class="co"># Enable the ssh-agent:</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true"></a><span class="bu">eval</span> <span class="kw">`</span><span class="fu">ssh-agent</span><span class="kw">`</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true"></a><span class="fu">ssh-add</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true"></a><span class="co"># Build with BuildKit and ssh-agent forwarding:</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true"></a><span class="bu">export</span> <span class="va">DOCKER_BUILDKIT=</span>1</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true"></a><span class="ex">docker</span> build --ssh default -t yourimage .</span></code></pre></div>
<p>Note that by default this will fail with an error about an unverified host; see the next best practice for details about to fix this.</p>
<h3 id="references-11">References</h3>
<ul>
<li><a href="https://docs.docker.com/develop/develop-images/build_enhancements/#using-ssh-to-access-private-data-in-builds">Using SSH with BuildKit</a> (docs.docker.com)</li>
<li><a href="https://man7.org/linux/man-pages/man1/ssh-add.1.html"><code>ssh-add</code> man page</a> (man7.org)</li>
<li><a href="https://man7.org/linux/man-pages/man1/ssh-agent.1.html"><code>ssh-agent</code> man page</a> (man7.org)</li>
</ul>
<h2 id="optional-pre-populate-ssh-known-hosts">Optional: Pre-populate SSH known hosts</h2>
<p>If you are using SSH within your Docker build, SSHing to a new host will ask you to verify the host’s key, which will fail because Docker builds don’t allow interactive input. You can disable checking the key with the <code>StrictHostKeyChecking=no</code> option, but this puts you at risk of man-in-the-middle attacks.</p>
<p>Better to copy in a <code>.ssh/known_hosts</code> prepopulated with the public key of the SSH host you will be accessing. You can download a key as follows:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true"></a>$ <span class="fu">ssh-keyscan</span> -t rsa ssh-host.example.com <span class="op">&gt;</span> ssh_known_hosts</span></code></pre></div>
<p>If you’re worried about attackers, compare it to the value in your existing <code>.ssh/known_hosts</code>. Some services like GitHub also post their SSH public key fingerprint, so you can check the value out-of-band.</p>
<p>Then in your <code>Dockerfile</code> you can copy in the <code>known_hosts</code> file:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true"></a><span class="kw">RUN</span> mkdir /root/.ssh &amp;&amp; chmod 700 /root/.ssh</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true"></a><span class="kw">COPY</span> ssh_known_hosts /root/.ssh/known_hosts</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true"></a><span class="kw">RUN</span> chmod 600 /root/.ssh/known_hosts</span></code></pre></div>
<h3 id="references-12">References</h3>
<ul>
<li><a href="https://serverfault.com/questions/132970/can-i-automatically-add-a-new-host-to-known-hosts/132973#132973">Automatically add new host to SSH known_hosts</a> (serverfault.com)</li>
<li><a href="https://www.openssh.com/manual.html">OpenSSH documentation</a> (openssh.com)</li>
<li><a href="https://help.github.com/en/github/authenticating-to-github/githubs-ssh-key-fingerprints">GitHub SSH public key fingerprints</a> (help.github.com)</li>
</ul>
<h1 id="best-practices-running-in-ci">Best practices: Running in CI</h1>
<h2 id="smoke-test">Add a smoke test for your image</h2>
<p>Your application might have bugs, and you’ll have unit tests and end-to-end tests to catch those. But you might also have issues with your Docker image: it might not start at all, for example.</p>
<p>So before you push your newly built image to the image registry, you should implement a smoke test. For example, if your image is a web server, you can run the newly built image and make sure you can send a successful HTTP query to the status endpoint:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true"></a><span class="im">import</span> time</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true"></a><span class="im">from</span> subprocess <span class="im">import</span> check_call</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true"></a><span class="im">from</span> urllib.request <span class="im">import</span> urlopen</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true"></a>check_call(</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true"></a>    <span class="st">&quot;docker run --rm --name=mycontainer -p 8080:80 -d httpd&quot;</span>.split()</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true"></a>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true"></a><span class="co"># Wait for the server to start. A better implementation would</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true"></a><span class="co"># poll in a loop:</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true"></a>time.sleep(<span class="dv">5</span>)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true"></a><span class="co"># Check if the server started (it&#39;ll throw an exception if not):</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true"></a><span class="cf">try</span>:</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true"></a>    urlopen(<span class="st">&quot;http://localhost:8080&quot;</span>).read()</span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true"></a><span class="cf">finally</span>:</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true"></a>    check_call(<span class="st">&quot;docker kill mycontainer&quot;</span>.split())</span></code></pre></div>
<p>The smoke test won’t catch all problems, but it will ensure you don’t push a completely broken image.</p>
<p>Notice the use of <code>--rm</code>, to ensure you’re not leaking containers. In a build system that spins up an empty environment each time this won’t matter, but in a persistent setup you don’t want to leak resources.</p>
<h3 id="references-13">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/test-your-docker-build/">Your Docker build needs a smoke test</a> (pythonspeed.com)</li>
</ul>
<h2 id="additional-checks">Additional checks: <code>hadolint</code>, size checks</h2>
<p>You can do additional checks on both your <code>Dockerfile</code> and image.</p>
<p>First, the <code>hadolint</code> <code>Dockerfile</code> linter will catch some problems, though very definitely not all. Additionally, some of its recommendations are completely wrong; for example, it recommends not using <code>apt-get upgrade</code>, which is a very bad recommendation. So only use it if you’re prepared to override many of its incorrect suggestions.</p>
<p>Second, it’s useful to check your image size isn’t any higher than a particular value: if you expect images to be 300-400MB and they’re suddenly 1GB, something has gone wrong. You can get the image size by running:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true"></a>$ <span class="ex">docker</span> image inspect --format=<span class="dt">{{.Size}}</span> yourorg/yourimage</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true"></a><span class="ex">237117212</span></span></code></pre></div>
<p>If you’re current image is 250MB, check for 300MB; better to be a little lenient so you don’t get spurious failures.</p>
<h3 id="references-14">References</h3>
<ul>
<li><a href="https://github.com/hadolint/hadolint"><code>hadolint</code></a> (github.com)</li>
<li><a href="https://docs.docker.com/engine/reference/commandline/image_inspect/"><code>docker image inspect</code> help</a> (docs.docker.com)</li>
</ul>
<h2 id="tag-branch">Tag images based on the version control branch</h2>
<p>You might have a CI system that automatically builds images from Git branches:</p>
<ol type="1">
<li>A developer pushes to branch <code>mybranch</code>.</li>
<li>The CI/build system automatically builds a new image, and pushes it to an image registry.</li>
</ol>
<p>You want to ensure that a developer working on a feature branch won’t accidentally overwrite the stable image used in production. The simplest solution is to have the CI script choose the image tag based on the branch.</p>
<p>While you’re at it, it’s worth tagging based on Git commit so you can also distinguish different images on the same branch:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true"></a><span class="va">GIT_BRANCH=$(</span><span class="fu">git</span> rev-parse --abbrev-ref HEAD<span class="va">)</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true"></a><span class="va">GIT_COMMIT=$(</span><span class="fu">git</span> rev-parse --short HEAD<span class="va">)</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true"></a><span class="va">IMAGE_NAME=</span><span class="st">&quot;imageregistry.example.com/org/theapp&quot;</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true"></a><span class="ex">docker</span> build -t <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_BRANCH</span><span class="st">&quot;</span> <span class="kw">\</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true"></a>             <span class="ex">-t</span> <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_COMMIT</span><span class="st">&quot;</span> .</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true"></a><span class="ex">docker</span> push <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_BRANCH</span><span class="st">&quot;</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true"></a><span class="ex">docker</span> push <span class="st">&quot;</span><span class="va">$IMAGE_NAME</span><span class="st">:</span><span class="va">$GIT_COMMIT</span><span class="st">&quot;</span></span></code></pre></div>
<h2 id="latest-tag">Don’t rely on the <code>latest</code> tag</h2>
<p>Using the <code>latest</code> tag as your main branch name is problematic:</p>
<ul>
<li>Its name is confusing, it’s not actually the latest image. From Docker’s perspective it’s just the default tag, it may well be an old image.</li>
<li>It’s easy to overwrite by mistake if you’re doing manual pushes, by forgetting to omit the tag.</li>
<li>If you’re using Kubernetes, it behaves differently for the <code>latest</code> tag vs other tags, which can lead to confusing behavior.</li>
</ul>
<p>If you want a default tag for production, better to choose some other name.</p>
<h3 id="references-15">References</h3>
<ul>
<li><a href="https://vsupalov.com/docker-latest-tag/">What’s wrong with the Docker <code>:latest</code> tag?</a> (vsupalov.com)</li>
<li><a href="https://kubernetes.io/docs/concepts/configuration/overview/#container-images">Kubernetes <code>imagePullPolicy</code> interaction with <code>latest</code></a> (kubernetes.io)</li>
</ul>
<h2 id="pull-in-ci">Warm up the build cache</h2>
<p>If you’re building your Docker image in your CI/build setup (GitLab CI, Jenkins, GitHub Actions, Azure Pipelines, etc.), in many cases each build will start with an empty local image cache. So you’ll want to make sure the previous version of the image is available locally so that it can be used when rebuilding. Otherwise your build might not use cached layers, and will always rebuild from scratch.</p>
<p>You’ll want to pull the image, and then use <code>--cache-from</code> to make sure Docker uses it:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true"></a><span class="ex">docker</span> pull yourimage <span class="kw">||</span> <span class="fu">true</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true"></a><span class="ex">docker</span> build -t yourimage <span class="kw">\</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true"></a>    <span class="ex">--build-arg</span> BUILDKIT_INLINE_CACHE=1 <span class="kw">\</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true"></a>    <span class="ex">--cache-from</span>=yourimage .</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true"></a><span class="ex">docker</span> push yourimage</span></code></pre></div>
<p>The <code>|| true</code> allows you to keep going even if the pull fails; this will be the case the first time you create the image.</p>
<p>The <code>--build-arg BUILDKIT_INLINE_CACHE=1</code> is necessary for this scheme to work with BuildKit. While this flag is not necessary in classic Docker builds, you may as well always set it so you don’t forget to enable it when you turn on BuildKit.</p>
<h3 id="references-16">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/speeding-up-docker-ci/">Speeding up Docker builds in CI</a> (pythonspeed.com)</li>
</ul>
<h2 id="pull-in-ci-2">Warm up the build cache for per-branch builds</h2>
<p>If you’re building multiple branches in parallel, and tagging images correspondingly, warming the cache won’t work the first time you build a new branch, even though it’s identical to your main branch. That is, if you do <code>docker pull yourimage:newbranch</code> and this is your first build of <code>newbranch</code>, that base image won’t be available. The solution is to pull and use <code>--cache-from</code> on multiple tags, both the branch and your default build.</p>
<p>Presuming your default production build is tagged with <code>production</code>:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true"></a><span class="va">BRANCH=$(</span><span class="fu">git</span> rev-parse --abbrev-ref HEAD<span class="va">)</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true"></a><span class="ex">docker</span> pull yourimage:production <span class="kw">||</span> <span class="fu">true</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true"></a><span class="ex">docker</span> pull yourimage:<span class="va">$BRANCH</span> <span class="kw">||</span> <span class="fu">true</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true"></a><span class="ex">docker</span> build -t yourimage:<span class="va">$BRANCH</span> <span class="kw">\</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true"></a>    <span class="ex">--cache-from</span>=yourimage:production <span class="kw">\</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true"></a>    <span class="ex">--cache-from</span>=yourimage:<span class="va">$BRANCH</span> <span class="kw">\</span></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true"></a>    <span class="ex">--build-arg</span> BUILDKIT_INLINE_CACHE=1 <span class="kw">\</span></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true"></a>    <span class="ex">.</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true"></a><span class="ex">docker</span> push yourimage:<span class="va">$BRANCH</span></span></code></pre></div>
<p>Instead of hard-coding something like <code>production</code>, you can also get the default branch for your Git repository (<code>master</code> or <code>main</code>):</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true"></a><span class="co"># ... see https://stackoverflow.com/q/28666357/6214034</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true"></a><span class="va">DEFAULT_BRANCH=$(</span><span class="fu">git</span> rev-parse --abbrev-ref origin/HEAD<span class="va">)</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true"></a><span class="va">DEFAULT_BRANCH=$(</span><span class="fu">basename</span> <span class="va">$DEFAULT_BRANCH)</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true"></a><span class="ex">docker</span> pull yourimage:<span class="va">$DEFAULT_BRANCH</span> <span class="kw">||</span> <span class="fu">true</span></span></code></pre></div>
<h2 id="optional-self-warming-cache-with-buildkit">Optional: Self-warming cache with BuildKit</h2>
<p>As an alternative to explicitly pulling the previous version of an image, you can also have Docker automatically pull only those layers it actually needs. In theory this is faster because layers that can’t be reused won’t need to be pulled.</p>
<p>You can do this using BuildKit, the alternative and improved Docker build backend. First, make sure you enable BuildKit in general using the <code>DOCKER_BUILDKIT</code> environment variable. Second, make sure you’re enabling inline caching metadata by passing in the <code>BUILDKIT_INLINE_CACHE</code> build arg. You’ll want to do the latter regardless!</p>
<p>The build script will look like this:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true"></a><span class="bu">export</span> <span class="va">DOCKER_BUILDKIT=</span>1</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true"></a><span class="ex">docker</span> build -t yourimage --cache-from=yourimage <span class="kw">\</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true"></a>       <span class="ex">--build-arg</span> BUILDKIT_INLINE_CACHE=1 .</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true"></a><span class="ex">docker</span> push yourimage</span></code></pre></div>
<p>Notice there is no need for a <code>docker pull</code>.</p>
<p>Note that:</p>
<ol type="1">
<li>There were some bugs in the version in 19.03, so you may wish to only use Docker 20.10 with this feature.</li>
<li>Some registries don’t work with this mechanism. Notably, the deprecated GitHub Packages registry will fail, and this will break caching altogether. You may wish to try the replacement GitHub Container Registry, in beta as of May 2021 and see if it works there.</li>
</ol>
<h3 id="references-17">References</h3>
<ul>
<li><a href="https://docs.docker.com/engine/reference/commandline/build/#specifying-external-cache-sources">External cache sources in <code>docker build</code></a> (docs.docker.com)</li>
</ul>
<h1 id="best-practices-make-debugging-easier">Best practices: Make debugging easier</h1>
<h2 id="stdout-logs">Write logs to <code>stdout</code> or <code>stderr</code></h2>
<p>In order to debug problems in a running application, you’ll want to make sure the logs from your application are captured.</p>
<p>Docker runtime environments will capture logs from <code>stdout</code> and <code>stderr</code>, so just make sure that’s where your logs go. You can then read the logs using tools like <code>docker logs</code> or <code>kubectl logs</code>, depending how you’re running your image, or redirect your logs elsewhere.</p>
<p>With Python’s built-in <code>logging</code> library, you can do:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true"></a><span class="im">import</span> sys, logging</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true"></a>logging.basicConfig(stream<span class="op">=</span>sys.stdout)</span></code></pre></div>
<p>In fact, by default Python’s <code>logging</code> will log to <code>stdout</code>, so technically you don’t have to do anything.</p>
<h2 id="faulthandler">Prepare for C crashes</h2>
<p>If your Python program crashes due to a segfault or some other bug in C code, you won’t get a traceback by default. And silent crashes are hard to debug.</p>
<p>To fix this, set the <code>PYTHONFAULTHANDLER</code> environment variable in your <code>Dockerfile</code>:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true"></a><span class="kw">ENV</span> PYTHONFAULTHANDLER=1</span></code></pre></div>
<p>And now you’ll get tracebacks from C crashes:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true"></a>$ <span class="ex">docker</span> run -it crasher</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true"></a><span class="ex">About</span> to crash...</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true"></a><span class="ex">Fatal</span> Python error: Segmentation fault</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true"></a><span class="ex">Current</span> thread 0x00007f2f75f98740 (most recent call first)<span class="bu">:</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true"></a>  <span class="ex">File</span> <span class="st">&quot;/usr/local/lib/python3.7/ctypes/__init__.py&quot;</span>, line 505 in string_at</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true"></a>  <span class="ex">File</span> <span class="st">&quot;crash.py&quot;</span>, line 3 in crash</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true"></a>  <span class="ex">File</span> <span class="st">&quot;crash.py&quot;</span>, line 5 in <span class="op">&lt;</span>module<span class="op">&gt;</span></span></code></pre></div>
<h3 id="references-18">References</h3>
<ul>
<li><a href="https://docs.python.org/3/library/faulthandler.html">Python’s <code>faulthandler</code> library</a> (docs.python.org)</li>
</ul>
<h2 id="identifiable">Record the build’s version control revision and branch</h2>
<p>It’s useful to know what exact revision of your application is running in production—or on your laptop—when you’re trying to reproduce a problem. You should therefore record the revision of your application’s source code, as well as the branch, in the image itself.</p>
<p>First, you can do this by adding metadata labels to the image:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true"></a></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true"></a><span class="va">GIT_COMMIT=$(</span><span class="fu">git</span> rev-parse --short HEAD<span class="va">)</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true"></a><span class="va">GIT_BRANCH=$(</span><span class="fu">git</span> rev-parse --abbrev-ref HEAD<span class="va">)</span></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true"></a><span class="ex">docker</span> build -t myimage:latest <span class="kw">\</span></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true"></a>      <span class="ex">--label</span> git-commit=<span class="va">$GIT_COMMIT</span> <span class="kw">\</span></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true"></a>      <span class="ex">--label</span> git-branch=<span class="va">$GIT_BRANCH</span> .</span></code></pre></div>
<p>You can inspect these labels using <code>docker inspect myimage</code>.</p>
<p>Second, you can also pass the git commit and branch into your image, by using the <code>ARG</code> command in your <code>Dockerfile</code>:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true"></a><span class="kw">ARG</span> git_commit</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true"></a><span class="kw">RUN</span> echo $git_commit &gt; /git-commit.txt</span></code></pre></div>
<p>And then passing the information in using <code>--build-arg</code>:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true"></a>$ <span class="ex">docker</span> build -t myimage --build-arg git_commit=<span class="va">$GIT_COMMIT</span> .</span></code></pre></div>
<p>You can then have the status API in your web application include this information, where it can be read by your monitoring infrastructure.</p>
<p>By default build arguments are exposed as environment variables only during the build. If you want the <code>ARG</code> to be available as an environment variable at runtime, you can do:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true"></a><span class="kw">ARG</span> git_commit</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true"></a><span class="kw">ENV</span> git_commit=$git_commit</span></code></pre></div>
<h3 id="references-19">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/identifying-images/">What’s running in production? Making your Docker images identifiable</a> (pythonspeed.com)</li>
<li><a href="https://nickjanetakis.com/blog/docker-tip-25-adding-metadata-to-your-docker-images-with-labels">Docker image labels</a> (nickjanetakis.com)</li>
<li><a href="https://docs.docker.com/engine/reference/builder/#arg">Docker build arguments</a> (docs.docker.com)</li>
<li><a href="https://git-scm.com/docs/git-rev-parse"><code>git rev-parse</code> documentation</a> (git-scm.com); personally I rely on StackOverflow search results because Git is so awful</li>
</ul>
<h2 id="useful-tools">Optional: Pre-install useful tools</h2>
<p>Unless you’re super-worried about security, it’s useful to have a few common debugging tools installed on your image. Since you <a href="#no-root">shouldn’t run as root</a>, you won’t be able to install these packages once the container is running.</p>
<p>For example, if you’re using the <code>slim</code> variants of the official Python image, you’ll want to install packages like <code>procps</code> and <code>net-tools</code> so you have access to <code>ps</code> and <code>netstat</code>:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get -y install procps net-tools</span></code></pre></div>
<p>Another useful tool, albeit with potential security risks, is the <code>manhole</code> library: it gives you a Python prompt into your running process. See the reference for details.</p>
<h3 id="references-20">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/live-debugging-python/">A Python prompt into your runner process: debugging with Manhole</a> (pythonspeed.com)</li>
<li><a href="https://python-manhole.readthedocs.io/en/latest/"><code>manhole</code> documentation</a> (python-manhole.readthedocs.io)</li>
</ul>
<h1 id="best-practices-correct-operation">Best practices: Correct operation</h1>
<h2 id="networkbind">Have public ports listen on <code>0.0.0.0</code></h2>
<p>If your server listens on <code>127.0.0.1</code>, you won’t be able to access it from the outside of the container. Unless this is your goal, make sure to listen on <code>0.0.0.0</code> so that it binds to the container’s external IP.</p>
<h3 id="references-21">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/docker-connection-refused/">Connection refused? Docker networking and how it impacts your image</a> (pythonspeed.com)</li>
</ul>
<h2 id="bash">Avoid bash, or at least use bash strict mode and <code>shellcheck</code></h2>
<p>Shell scripting is a recipe for failure. Whereas errors in a Python script will cause an exception, in shell scripts the default is to silently continue. The following script, for example, will print “Success!”, which is probably not what you want.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true"></a><span class="bu">export</span> <span class="va">VAR=$(</span><span class="bu">echo</span> hello <span class="kw">|</span> <span class="ex">nonexistentprogram</span><span class="va">)</span></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true"></a><span class="bu">echo</span> <span class="st">&quot;Success!&quot;</span></span></code></pre></div>
<p>You can make many errors cause the script to stop by using bash strict mode (<code>set -euo pipefail</code>), but even that won’t work in this case:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true"></a><span class="bu">export</span> <span class="va">VAR=$(</span><span class="kw">set</span> <span class="ex">-euo</span> pipefail<span class="kw">;</span> <span class="bu">echo</span> hello <span class="kw">|</span> <span class="ex">nonexistentprogram</span><span class="va">)</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true"></a><span class="bu">echo</span> <span class="st">&quot;Success!&quot;</span></span></code></pre></div>
<p>This will still print “Success!”. Do you know how to fix that?</p>
<p>There are two solutions to the limits of shell scripting:</p>
<ol type="1">
<li>Use <code>set -euo pipefail</code> at the start of every <code>bash</code> script, use the <code>shellcheck</code> tool to lint your shell script, and make sure you’re using the latest version of <code>shellcheck</code> (the one in your Linux distribution may not catch all problems!).</li>
<li>Replace the shell script with a Python script, since you already have Python installed.</li>
</ol>
<h3 id="references-22">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/shell-scripts/">Please don’t use shell scripts</a> (pythonspeed.com)</li>
<li><a href="http://redsymbol.net/articles/unofficial-bash-strict-mode/">bash strict mode</a> (redsymbol.net)</li>
<li><a href="https://www.shellcheck.net/">The <code>shellcheck</code> shell linter</a> (shellcheck.net)</li>
</ul>
<h2 id="shutdown">Ensure fast shutdowns</h2>
<p>If you don’t configure your image correctly, signals won’t be delivered to your process, and shutdowns will take 10 seconds: first the original signal will be used, then after a timeout SIGKILL will be used, shutting it down with extreme prejudice (the same way <code>kill -9</code> does).</p>
<p>To get signal delivery working:</p>
<ol type="1">
<li>Use the <code>[]</code> syntax of <code>ENTRYPOINT</code> and <code>CMD</code>, not the shell syntax.</li>
<li>If your entrypoint script is a shell script, make sure it ends by using the shell <code>exec</code> command to run your final program. This will replace the shell process with your program. In Python you can use <code>os.execve</code> or one of the related functions.</li>
</ol>
<p>For example, let’s say you have a <code>Dockerfile</code> that runs a script called <code>entrypoint.sh</code>. The shell script should look like this:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true"></a></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true"></a><span class="co"># BAD:</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true"></a><span class="co"># python myserver.py</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true"></a></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true"></a><span class="co"># GOOD:</span></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true"></a><span class="bu">exec</span> python myserver.py</span></code></pre></div>
<p>And the <code>Dockerfile</code>:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true"></a><span class="co"># BAD:</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true"></a><span class="co"># ENTRYPOINT ./entrypoint.sh</span></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true"></a></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true"></a><span class="co"># GOOD:</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;./entrypoint.sh&quot;</span>]</span></code></pre></div>
<p>Additionally, there are two other problems you might encounter:</p>
<ol type="1">
<li>If you’re using a shell script there’s another failure mode involving pipes: don’t use them on the final command in your entrypoint script.</li>
<li>If your program expects a signal other than <code>SIGTERM</code>, use the <code>STOPSIGNAL</code> <code>Dockerfile</code> command. For example, if your program shuts down just fine outside of Docker when you hit Ctrl-C and a <code>KeyboardInterrupt</code> is raised, that means it expects a <code>SIGINT</code>, and you should use <code>STOPSIGNAL INT</code>.</li>
</ol>
<p>Another approach to Ctrl-C handling can be done with <code>tini</code>, see the next section.</p>
<h3 id="references-23">References</h3>
<ul>
<li><a href="https://hynek.me/articles/docker-signals/">Why your Dockerized application isn’t receiving signals</a> (hynek.me)</li>
<li><a href="https://docs.docker.com/engine/reference/builder/#stopsignal"><code>STOPSIGNAL</code> reference</a> (docs.docker.com)</li>
<li><a href="https://docs.python.org/3/library/os.html#os.execl"><code>os.exec*</code> documentation</a> (docs.python.org)</li>
</ul>
<h2 id="init">Add an <code>init</code> process</h2>
<p>Unix systems are designed to have an <code>init</code> process with PID 1 to help deal with existing processes. If you’re running subprocesses in your image you’ll therefore want to ensure you have one setup.</p>
<p>With Docker you can do this on the command-line when you run an image (<code>docker run --init</code>). Not all runtime environments have this option, though, so it’s likely better to include one in your <code>Dockerfile</code>:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get install -y tini</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true"></a><span class="kw">COPY</span> your-entrypoint.sh .</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;tini&quot;</span>, <span class="st">&quot;--&quot;</span>, <span class="st">&quot;./your-entrypoint.sh&quot;</span>]</span></code></pre></div>
<p>One useful option to add to <code>tini</code> is the <code>-g</code> option:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;tini&quot;</span>, <span class="st">&quot;-g&quot;</span>, <span class="st">&quot;--&quot;</span>, <span class="st">&quot;./your-entrypoint.sh&quot;</span>]</span></code></pre></div>
<p>When the parent <code>tini</code> process is killed, instead of just killing the top-level process (a shell running <code>your-entrypoint.sh</code> in the above example), it will send a signal to <em>all</em> descendant processes in the main process group. In practice that is likely to be all the container’s processes. This is almost always the behavior you want: shutting down kills all processes immediately.</p>
<h3 id="references-24">References</h3>
<ul>
<li><a href="https://github.com/krallin/tini">The <code>tini</code> init process</a> (github.com)</li>
</ul>
<h2 id="deb-interactive">Set a non-interactive frontend for Debian/Ubuntu package installs</h2>
<p>When installing packages via <code>apt-get</code> on Debian, Ubuntu, or Debian-based images like the official <code>python</code> image, you don’t want the build trying to ask you questions about how to configure the packages you are installing. You do so by setting the <code>DEBIAN_FRONTEND</code> environment variable to <code>noninteractive</code>.</p>
<p>One way to do so is like this:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true"></a><span class="kw">RUN</span> export DEBIAN_FRONTEND=noninteractive &amp;&amp; \</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true"></a>    apt-get install -y gcc</span></code></pre></div>
<h2 id="health-checks">Add health checks</h2>
<p>Your running container may lock up or stop working due to bugs or other problems. Most container runtimes can therefore monitor running containers and check if they’re still alive—but only if you configure health checks.</p>
<p>There are at least two different ways to configure health checks, depending on your runtime environment:</p>
<ol type="1">
<li>The <code>Dockerfile</code> format supports one kind, which is used by tools like Docker Swarm.</li>
<li>Kubernetes has its own mechanism, and doesn’t support the one in <code>Dockerfile</code>.</li>
</ol>
<p>Here’s an example of the <code>Dockerfile</code> variant, which uses the <code>HEALTHCHECK</code> command:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true"></a><span class="kw">HEALTHCHECK</span> --interval=3s --timeout=1s \</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true"></a>  <span class="kw">CMD</span> [<span class="st">&quot;python&quot;</span>, <span class="st">&quot;-c&quot;</span>, \</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true"></a>       <span class="st">&quot;from urllib.request import urlopen; </span><span class="op">\</span></span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true"></a><span class="st">        urlopen(&#39;http://localhost:8000&#39;).read()&quot;</span>]</span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;python&quot;</span>, <span class="st">&quot;-m&quot;</span>, <span class="st">&quot;http.server&quot;</span>]</span></code></pre></div>
<h3 id="references-25">References</h3>
<ul>
<li><a href="https://docs.docker.com/engine/reference/builder/#healthcheck"><code>Dockerfile</code>’s <code>HEALTHCHECK</code> command</a> (docs.docker.com)</li>
<li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">Kubernetes health checks</a> (kubernetes.io)</li>
<li><a href="https://github.com/willfarrell/docker-autoheal">docker-autoheal</a> is a tool that will automatically restart Docker containers that failed their healthcheck.</li>
</ul>
<h2 id="bytecode">Pre-compile bytecode for faster startup</h2>
<p>Python compiles source code to <code>.pyc</code> files, the corresponding bytecode. If <code>.pyc</code> files aren’t available in your Docker image, your application will need to compile them, and this can lead to much slower startup. This leads to a tradeoff between startup performance and image size:</p>
<ul>
<li>If you want your container to start as quickly as possible, you will want to precompile the <code>.pyc</code> files.</li>
<li>If you want your image to be as small as possible, you want to have no <code>.pyc</code> files at all in your image; you can make sure <code>pip</code> doesn’t compile them by doing <code>pip install --no-compile</code>, which will also speed image build time slightly.</li>
</ul>
<p>Presuming you want fast startup, add the following to the end of your <code>Dockerfile</code> to create <code>.pyc</code> files for all installed packages:</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true"></a><span class="kw">RUN</span> python -c <span class="st">&quot;import compileall; compileall.compile_path(maxlevels=10)&quot;</span></span></code></pre></div>
<p>If you also have code in the current directory you want to compile, you can compile it like so:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true"></a><span class="kw">RUN</span> python -m compileall yourpackage/</span></code></pre></div>
<h3 id="references-26">References</h3>
<ul>
<li><a href="https://docs.python.org/3/library/compileall.html">The <code>compileall</code> module</a> (docs.python.org)</li>
</ul>
<h1 id="best-practices-reproducible-builds">Best practices: Reproducible builds</h1>
<p>Imagine you start with a certain revision of your source code and build a Docker image. A month later, you start with the same revision, fix a minor bug, and build a new image from scratch.</p>
<p>If your build is not reproducible, you might end up installing different versions of your Python dependencies, system packages, and perhaps even a different version of the operating system. The resulting image might have new bugs, behave in unexpected ways, or even fail to work completely due to incompatible changes. A minor bug fix has now spiraled out of control.</p>
<p>But if your build is reproducible, your new image will be mostly the same as your old image: the only difference will be the bug fix.</p>
<p>Your goal then is to have a reproducible build: the same inputs should result in the same output.</p>
<h2 id="base">Choose a stable base image and tag</h2>
<p>When choosing a base image for your <code>Dockerfile</code>, you will likely want:</p>
<ul>
<li><strong>Stability:</strong> You want a build today to give you the same basic set of libraries, directory structure, and infrastructure as a build tomorrow, otherwise your application will randomly break.</li>
<li><strong>Security updates:</strong> You want the base image to be well-maintained, so that you get security updates for the base operating system in a timely manner.</li>
<li><strong>Up-to-date dependencies:</strong> Unless you’re building a very simple application, you will likely depend on operating system-installed libraries and applications, for example a C compiler. Ideally these dependencies would be fairly modern.</li>
<li><strong>Extensive dependencies:</strong> Some applications will require less popular dependencies—a base image with access to a large number of libraries makes this easier.</li>
<li><strong>Up-to-date Python:</strong> Having an up-to-date Python available out of the box saves you some effort.</li>
<li><strong>Small images:</strong> All things being equal, it’s better to have a smaller Docker image than a bigger Docker image.</li>
</ul>
<p>Ubuntu Long Term Support (LTS) releases, Debian Stable, and RedHat Enterprise Linux are all reasonable candidates, since they aim for backwards compatibility while still providing security updates and critical bug fixes. As I <a href="#no-alpine">discuss later on</a>, I recommend avoiding Alpine Linux.</p>
<p>Of course, each of the distributions has different variations available, including non-LTS releases. So when you choose a base image, you’ll need to make sure to specify a particular release using a tag:</p>
<ul>
<li><strong>Bad:</strong> <code>FROM ubuntu</code>—today this might be Ubuntu 22.04, eventually it will be Ubuntu 24.04.</li>
<li><strong>Good:</strong> <code>FROM ubuntu:22.04</code>, <code>FROM debian:11</code> aka <code>FROM debian:bullseye</code>.</li>
</ul>
<p>Here’s a comparison between the three. Newer releases may be better in some cases, insofar as they will have more up-to-date system packages.</p>
<table>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Released</th>
<th>End-of-life</th>
<th>Python versions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>RHEL 8 + clones</td>
<td>May 2019</td>
<td>May 2024</td>
<td>3.9, 3.8, 3.6</td>
</tr>
<tr class="even">
<td>RHEL 9 + clones</td>
<td>May 2022</td>
<td>May 2027</td>
<td>3.9</td>
</tr>
<tr class="odd">
<td>Debian 11</td>
<td>Aug 2021</td>
<td>Aug 2025</td>
<td>3.9</td>
</tr>
<tr class="even">
<td>Ubuntu 20.04</td>
<td>Apr 2020</td>
<td>Apr 2025</td>
<td>3.9, 3.8</td>
</tr>
<tr class="odd">
<td>Ubuntu 22.04</td>
<td>Apr 2022</td>
<td>Apr 2027</td>
<td>3.10</td>
</tr>
</tbody>
</table>
<p>Comparing those distributions that include Python 3.9 at the time of writing (September 2022), they have different point releases, none of which match the latest version (3.9.14 which was released in September 2022):</p>
<table>
<thead>
<tr class="header">
<th>Image</th>
<th>3.9 release</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Debian 11</td>
<td>3.9.2</td>
</tr>
<tr class="even">
<td>Ubuntu 20.04</td>
<td>3.9.5</td>
</tr>
<tr class="odd">
<td>RHEL 8</td>
<td>3.9.7</td>
</tr>
<tr class="even">
<td>RHEL 9</td>
<td>3.9.10</td>
</tr>
</tbody>
</table>
<p>Another option is the “official” Docker Python image, the one blessed by Docker-the-company. It has variants with pretty much every version of Python available, so you’re not tied to whichever versions Linux distributions decided to include or backport. In particular, you’ll want the variant based on Debian Stable, the most-up-to-date being <code>bullseye</code>. And I also recommend using the <code>slim</code> variant to get a smaller base image.</p>
<p>Given these choices, you can choose different levels of reproducibility:</p>
<ul>
<li><code>python:3.10-slim-bullseye</code> is the latest sub-release of Python 3.10, installed on top of Debian “Bullseye” 11. At the time of writing this will be 3.10.7, later it will be 3.10.8, and so on.</li>
<li><code>python:3.10.7-slim-bullseye</code> is a specific sub-release, Python 3.10.7. This tag might still point to different images over time, however; it might be updated with newer releases of <code>pip</code>, for example, or newer system packages.</li>
<li><code>python@sha256:7e8d32d9e8c20a3626146a932ecf98c3fc2a4b1100b008193b835acc2ab88018</code> is a specific image, unchanging even if the tags get pointed at new images. There’s no guarantee the Hub will keep old images around though, so you may wish to copy the image into your registry, or even create your own custom base image. The latter is covered below.</li>
</ul>
<p>Note that at the moment the Python packaged by the official images is not as fast as some of the alternatives. For example, Python runs 10-20% faster using Ubuntu and Debian’s version of Python 3.9. So for older versions of Python, if performance is critical you may wish to use Ubuntu or Debian. For Python 3.10 there doesn’t appear to be much of a difference in performance.</p>
<h3 id="references-27">References</h3>
<ul>
<li><a href="https://hub.docker.com/_/python">“Official” Python base image</a> (hub.docker.com)</li>
<li><a href="https://hub.docker.com/_/debian">Debian base image</a> (hub.docker.com)</li>
<li><a href="https://hub.docker.com/_/ubuntu">Ubuntu base image</a> (hub.docker.com)</li>
<li><a href="https://developers.redhat.com/products/rhel/ubi">RedHat Universal Base Images</a> (developers.redhat.com)</li>
<li><a href="https://docs.docker.com/engine/reference/commandline/pull/#pull-an-image-by-digest-immutable-identifier">Pulling an image by digest</a> (docs.docker.com)</li>
<li><a href="https://pythonspeed.com/articles/base-image-python-docker-images/">Choosing a base image for your Python application</a> (pythonspeed.com)</li>
<li><a href="https://pythonspeed.com/articles/faster-python/">Performance comparison between different Python builds</a> (pythonspeed.com)</li>
</ul>
<h2 id="redhat-compatible-base-images">RedHat-compatible base images</h2>
<p>If you want to use a RedHat-compatible base image, but not pay for RedHat Enterprise Linux, you would in the past have used CentOS. CentOS 8 is however no longer a stable, maintained distribution; you should not be using it.</p>
<p>Supported alternatives include:</p>
<ul>
<li>RedHat’s own Universal Base Images. Not all RedHat packages are available in these images, but they should include most popular packages.</li>
<li>Oracle Linux is a pre-existing clone of RedHat Enterprise Linux, maintained by Oracle. You can pay for commercial support, but you can also just use it for free.</li>
<li>AlmaLinux was created by CloudLinux, a commercial Linux vendor who used to base their product on CentOS.</li>
<li>RockyLinux was started by one of the original creators of CentOS.</li>
</ul>
<p>Oracle Linux has been in existence for much longer, so it has better tooling support from things like security scanners. If you’re using the Trivy security scanner, v0.23 and later support AlmaLinux and Rocky Linux too. Otherwise, the last three options don’t seem much different.</p>
<h3 id="references-28">References</h3>
<ul>
<li><a href="https://developers.redhat.com/products/rhel/ubi">RedHat Universal Base Images</a> (developers.redhat.com)</li>
<li><a href="https://hub.docker.com/u/redhat"><code>redhat/ubi8</code> and <code>redhat/ubi9</code> on Docker Hub</a> (hub.docker.com)</li>
<li><a href="https://catalog.redhat.com/software/containers/search">RedHat’s container image registry</a> (catalog.redhat.com)</li>
<li><a href="https://hub.docker.com/_/oraclelinux"><code>oraclelinux</code> image</a> (hub.docker.com)</li>
<li><a href="https://hub.docker.com/_/almalinux"><code>almalinux</code> image</a> (hub.docker.com)</li>
<li><a href="https://hub.docker.com/_/rockylinux"><code>rockylinux</code> image</a> (hub.docker.com)</li>
</ul>
<h2 id="pin-python">Pin your Python dependencies</h2>
<p>If you run:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true"></a><span class="kw">RUN</span> pip install flask</span></code></pre></div>
<p>You will get one version today, and potentially a very different version in 6 months. So when you install Python dependencies you want to install “pinned” versions, specific versions of the package and its transitive dependencies; <code>flask</code> depends on other libraries, and we want them to be pinned too.</p>
<p>In general you want to maintain two lists of dependencies:</p>
<ol type="1">
<li>The high-level dependencies of your application, the particular libraries you’re importing. For example, <code>flask</code> and <code>pandas</code>.</li>
<li>The pinned transitive dependencies, which you use to install the dependencies as part of the Docker build.</li>
</ol>
<p>The high-level dependencies are used to regenerate the transitive dependencies; see below in <a href="#update-dependencies">the section on updating dependencies</a>.</p>
<p>There are three tools for handling these two sets of dependency files: <code>pip-tools</code> (the simplest of the three), <code>poetry</code>, and <code>pipenv</code>.</p>
<p>With <code>pip-tools</code>, for example, you would have a <code>requirements.in</code> file that looks like this:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true"></a>flask</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true"></a>pandas</span></code></pre></div>
<p>You would then compile it to a <code>requirements.txt</code> by running <code>pip-compile --generate-hashes requirements.in</code>. Hashes are useful to ensure you’re getting the exact same package, and that it hasn’t been replaced on PyPI by a malicious attacker. The resulting <code>requirements.txt</code> would look like this:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true"></a>click==7.0 \</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true"></a>    --hash=sha256:2335065e6395b9e67ca716de5f7526736bfa6ceead690adf616d925bdc622b13 \</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true"></a>    --hash=sha256:5b94b49521f6456670fdb30cd82a4eca9412788a93fa6dd6df72c94d5a8ff2d7 \</span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true"></a>    # via flask</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true"></a>flask==1.1.1 \</span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true"></a>    --hash=sha256:13f9f196f330c7c2c5d7a5cf91af894110ca0215ac051b5844701f2bfd934d52 \</span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true"></a>    --hash=sha256:45eb5a6fd193d6cf7e0cf5d8a5b31f83d5faae0293695626f539a823e93b13f6</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true"></a>itsdangerous==1.1.0 \</span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true"></a>    --hash=sha256:321b033d07f2a4136d3ec762eac9f16a10ccd60f53c0c91af90217ace7ba1f19 \</span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true"></a>    --hash=sha256:b12271b2047cb23eeb98c8b5622e2e5c5e9abd9784a153e9d8ef9cb4dd09d749 \</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true"></a>    # via flask</span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true"></a>...</span></code></pre></div>
<p>Your <code>Dockerfile</code> would do:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span></code></pre></div>
<h3 id="references-29">References</h3>
<ul>
<li><a href="https://blog.ometer.com/2017/01/10/dear-package-managers-dependency-resolution-results-should-be-in-version-control/">Dear package managers: dependency resolution results should be in version control</a> (blog.ometer.com)</li>
<li><a href="https://pythonspeed.com/articles/pipenv-docker/">Faster Docker builds with pipenv, poetry, and pip-tools</a> (pythonspeed.com)</li>
<li><a href="https://github.com/jazzband/pip-tools"><code>pip-tools</code> documentation</a> (github.com)</li>
<li><a href="https://python-poetry.org/"><code>poetry</code> documentation</a> (python-poetry.org)</li>
<li><a href="https://pipenv.kennethreitz.org/en/latest/"><code>pipenv</code> documentation</a> (pipenv.kennethreitz.org)</li>
</ul>
<h2 id="update-dependencies">∞ Update all pinned dependencies once a month ∞</h2>
<p>As we discussed above, in order to ensure reproducible builds you want to keep the following from changing by pinning them to specific versions:</p>
<ol type="1">
<li>Base image.</li>
<li>System packages (optional).</li>
<li>Version of Python.</li>
<li>Python dependencies.</li>
</ol>
<p>It can be tempting to leave these versions unchanged for long periods of time, to ensure a stable baseline for your application. This would be a mistake:</p>
<ol type="1">
<li>You need to get security updates and other critical bug fixes that you’ve missed.</li>
<li>A series of small upgrades are much safer and easier than one massive upgrade.</li>
</ol>
<p>To expand on the second point: if you only upgrade dependencies once a year, you now potentially have a new base operating system, a new version of Python, and major changes to three libraries you depend on. If these updates cause your program to have issues, it can be difficult to figure out what caused them.</p>
<p>It’s also difficult to convince management that you should spend a week upgrading your dependencies; what about all those features and bug fixes on the product plan?</p>
<p>On the other hand, if every month you update your dependencies, you will only be changing one or two things at a time. That means problems can be easily pinpointed: if you’ve only updated Flask this month, it’s clear what caused the regression in your application.</p>
<p>What’s more, the chunks of time you spend on these upgrades will also be much shorter, causing less disruption to other work.</p>
<p>This doesn’t mean that every time a new major, incompatible release comes out you should immediately rewrite your software. “Once a month” is a starting point, not the correct timespan for every dependency. But if you decide not to upgrade a dependency for now, make it an explicit decision with an explicit and ideally short-term deadline for when you will upgrade.</p>
<h2 id="pin-system">Optional: Pin system packages</h2>
<p>One of the benefits of using a stable base operating system like Debian, Ubuntu LTS, or RHEL is compatibility over time. As long as you stick to a major release, the maintainers will try to release critical bug fixes and security updates to libraries without making incompatible changes.</p>
<p>This is the theory.</p>
<p>In practice, that might not be good enough for you. If you really want to ensure specific package versions get installed, instead of doing:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true"></a><span class="kw">RUN</span> apt-get install -y nginx</span></code></pre></div>
<p>You can install a specific release:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true"></a><span class="kw">RUN</span> apt-get install -y nginx=1.14.2-2+deb10u3</span></code></pre></div>
<p>On RedHat-based images, <code>dnf</code> and <code>yum</code> support a similar syntax.</p>
<p>If you want to be even more paranoid about stability, you may want to look into Nix, which is a completely different approach to software packaging.</p>
<h3 id="references-30">References</h3>
<ul>
<li><a href="https://www.debian.org/doc/user-manuals#apt-guide">APT User’s Guide</a> (debian.org)</li>
<li><a href="https://dnf.readthedocs.io/en/latest/index.html">DNF Documentation</a> (dnf.readthedocs.io)</li>
<li><a href="https://nixos.org/nix/">The Nix package manager</a> (nixos.org)</li>
</ul>
<h2 id="custom-base-image">Optional: Create a custom base image</h2>
<p>If your <code>Dockerfile</code> looks like this:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get -y upgrade</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true"></a><span class="co"># Your actual application:</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true"></a><span class="co"># ...</span></span></code></pre></div>
<p>Then rebuilding your image from scratch with security updates once a week will lead to a lack of reproducibility: the base image will change over time, as will the security updates.</p>
<p>You can just assume that security updates won’t make too much of a semantic difference, and live with it. Or, you can create a custom base image to ensure reproducibility.</p>
<p>Here is an example of how you might do that; you might need to modify this scheme to meet your particular workflow. You create a <code>Dockerfile.base</code> that looks like this:</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get -y upgrade</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true"></a><span class="co"># ...whatever else you want in a base image...</span></span></code></pre></div>
<p>And then build it with both a tag and label that store some permanent identifier, the current date for example. You make sure never to change the image for the tag once it’s created:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true"></a>$ <span class="va">TODAY=</span>2020-05-29</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true"></a>$ <span class="ex">docker</span> build -f Dockerfile.base -t yourorg/baseimage <span class="kw">\</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true"></a>    <span class="ex">-t</span> yourorg/baseimage:<span class="va">$TODAY</span> --label BASE_BUILT=<span class="va">$TODAY</span> .</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true"></a>$ <span class="ex">docker</span> push yourorg/baseimage</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true"></a>$ <span class="ex">docker</span> push yourorg/baseimage:<span class="va">$TODAY</span></span></code></pre></div>
<p>Now you can build your normal image using that base image:</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true"></a><span class="kw">FROM</span> yourog/baseimage</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true"></a><span class="co"># ... etc ...</span></span></code></pre></div>
<p>If you ever need to know which base image was used to create the image, you can just look for the label:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true"></a>$ <span class="ex">docker</span> inspect myapp <span class="kw">|</span> <span class="fu">grep</span> BASE_BUILT</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true"></a>       <span class="st">&quot;BASE_BUILT&quot;</span>: <span class="st">&quot;2020-05-29&quot;</span></span></code></pre></div>
<p>And you can always rebuild with that exact version of the base image if need be:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true"></a><span class="kw">FROM</span> yourorg/baseimage:2020-05-29</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true"></a><span class="co"># ... etc ...</span></span></code></pre></div>
<h1 id="best-practices-faster-builds">Best practices: Faster builds</h1>
<h2 id="no-alpine">Don’t use Alpine Linux</h2>
<p>When installing Python packages from PyPI, <code>pip</code> can usually speed up installation by downloading pre-compiled binary wheels provided by the package maintainers. However, these wheels don’t work on Alpine Linux, which means you have to rebuild every single package yourself.</p>
<p>For example, if you want to install <code>pandas</code> and <code>matplotlib</code> from PyPI, build time will go from ~30 seconds on a Debian-based image to ~1500 seconds on Alpine, a 50× increase. Alpine Linux has other issues as well, like a slower standard C library; see the reference below for details.</p>
<p>It is now possible to publish to PyPI <code>musllinux</code> wheels that are compatible with Alpine, based on the spec in PEP 656. But it’s still up to every package maintainer to create these wheels, so it may take a while.</p>
<h3 id="references-31">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/alpine-docker-python/">Using Alpine can make Python Docker builds 50× slower</a> (pythonspeed.com)</li>
<li><a href="https://peps.python.org/pep-0656/">PEP 656</a> (python.org)</li>
</ul>
<h2 id="copy-late"><code>COPY</code> in files only when needed</h2>
<p>To a first approximation, each command in the <code>Dockerfile</code> creates a new layer in the new image. Docker builds can use cached layers to speed up the build: if the command hasn’t changed, or input files haven’t changed if you’re doing a <code>COPY</code>, the cached layer can be reused.</p>
<p>If a layer can’t be loaded from the cache, none of the later steps in the <code>Dockerfile</code> can use caching either. So you want to ensure you don’t invalidate the cache unnecessarily.</p>
<p>Consider the following <code>Dockerfile</code>:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get install -y gcc</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span></code></pre></div>
<p>If <code>requirements.txt</code> changes, that will invalidate the <code>apt-get</code> command too, even though <code>apt-get</code> doesn’t need <code>requirements.txt</code>. Better to copy in the file only when you need it:</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get install -y gcc</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span></code></pre></div>
<p>More broadly, you’ll want commands that don’t depend on <code>COPY</code>, like <code>apt-get</code> or <code>dnf</code>, to run before commands that do.</p>
<h3 id="references-32">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/docker-caching-model/">Faster or slower: the basics of Docker build caching</a> (pythonspeed.com)</li>
</ul>
<h2 id="install-dependencies-first">Install dependencies separately from your code</h2>
<p>Expanding on the previous point, if you’re installing your Python application’s dependencies via <code>setup.py</code>, any change to your application code will invalidate the list of Python dependencies you installed. So that means downloading and installing all the packages from PyPI again.</p>
<p>Instead of listing dependencies in <code>setup.py</code>, you should list dependencies in a separate file, either <code>requirements.txt</code> or the configuration files used by <code>poetry</code> or <code>pipenv</code>. Then you can install 3rd party libraries first and have that layer cached:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true"></a><span class="kw">RUN</span> pip install .</span></code></pre></div>
<p>See the best practices for Poetry (<a href="#poetry">ref</a>), Pipenv (<a href="#pipenv">ref</a>), and Conda (<a href="#conda">ref</a>) for details on installing dependencies with those tools.</p>
<h3 id="references-33">References</h3>
<ul>
<li><a href="https://pip.pypa.io/en/stable/reference/pip_install/#requirements-file-format"><code>requirements.txt</code> file format</a> (pip.pypa.io)</li>
</ul>
<h2 id="arg-late">Use <code>ARG</code> only when needed</h2>
<p>Just like changes to files can invalidate the cache, so can changing build arguments passed in to a <code>ARG</code> command. So much like you want to only <code>COPY</code> in files when you actually need them, you also only want to add the <code>ARG</code> to the <code>Dockerfile</code> at the point where you’ll actually be using it.</p>
<p>For example, let’s say you want to pass in the Git commit to the build. The Git commit will change on every build, so don’t do the following or you’ll completely disable build caching:</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true"></a><span class="co"># Bad location, it&#39;s not used yet and will invalidate cache:</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true"></a><span class="kw">ARG</span> git_commit</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true"></a><span class="kw">RUN</span> apt-get install ...</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true"></a><span class="kw">RUN</span> pip install ...</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true"></a><span class="kw">RUN</span> echo $git_commit &gt; /var/run/git-commit.txt</span></code></pre></div>
<p>Instead, do this:</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true"></a><span class="kw">RUN</span> apt-get install ...</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true"></a><span class="kw">RUN</span> pip install ...</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true"></a></span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true"></a><span class="co"># Good location, won&#39;t invalidate cache of apt-get or pip:</span></span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true"></a><span class="kw">ARG</span> git_commit</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true"></a><span class="kw">RUN</span> echo $git_commit &gt; /var/run/git-commit.txt</span></code></pre></div>
<h2 id="use-docker-build---label-instead-of-label">Use <code>docker build --label</code> instead of <code>LABEL</code></h2>
<p>If you’re passing in a build argument only so you can use it for a <code>LABEL</code>, e.g.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true"></a><span class="co"># ...</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true"></a><span class="kw">ARG</span> git_commit</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true"></a><span class="kw">LABEL</span> git_commit=$git_commit</span></code></pre></div>
<p>Better to just set the label using the <code>--label</code> argument to <code>docker build</code>, e.g.</p>
<pre><code>$ docker build --label=git_commit=$GIT_COMMIT</code></pre>
<p>This way you don’t have to worry about the impact of the <code>ARG</code> on layer caching.</p>
<h1 id="best-practices-small-images">Best practices: Small images</h1>
<h2 id="temporary-files">Keep temporary files from ending up in a layer</h2>
<p>Each <code>RUN</code> and <code>COPY</code> command adds another layer to your Docker image, rather like commits in the Git history. As a result deleting files that are in a previous layer won’t shrink your image, since they will still be present in the previous layer:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true"></a><span class="kw">RUN</span> wget https://example.com/largefile.tar.gz</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true"></a><span class="kw">RUN</span> tar xvfz largefile.tar.gz</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true"></a><span class="kw">RUN</span> largefile/install.sh</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true"></a><span class="co"># BAD, This will not shrink your image:</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true"></a><span class="kw">RUN</span> rm -rf largefile.tar.gz largefile/</span></code></pre></div>
<p>Instead, you can combine these commands into a single layer, and then the temporary files won’t end up in the image:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true"></a><span class="co"># GOOD, temporary files deleted before RUN ends:</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true"></a><span class="kw">RUN</span> wget https://example.com/largefile.tar.gz &amp;&amp; \</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true"></a>    tar xvfz largefile.tar.gz &amp;&amp; \</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true"></a>    largefile/install.sh &amp;&amp; \</span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true"></a>    rm -rf largefile.tar.gz largefile/</span></code></pre></div>
<p>This works because files are only stored in a layer at the end of the <code>RUN</code>. If the file doesn’t exist when the <code>RUN</code> finishes, it won’t get stored.</p>
<h3 id="references-34">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/smaller-docker-images/">Shrinking your Python application’s Docker image: an overview</a> (pythonspeed.com)</li>
</ul>
<h2 id="dive">Find large layers and files with <code>dive</code></h2>
<p>To figure out why your image is too large, you can use <code>docker image history yourimage</code>, but that just tells you which layers are using a lot of disk space. The <code>dive</code> tools shows you per-layer sizes, and shows the differences and what files were added, so you can get a much more nuanced view of where image size is coming from.</p>
<h3 id="references-35">References</h3>
<ul>
<li><a href="https://github.com/wagoodman/dive"><code>dive</code></a> (github.com)</li>
</ul>
<h2 id="dockerignore">Add files to <code>.dockerignore</code></h2>
<p>When you run <code>docker build</code>, all files in the source directory are copied in to the context. The context is then used as the source of files copied in with the <code>COPY</code> or <code>ADD</code> commands. Usually you’ll pass in the current directory as the source directory.</p>
<p>This has some issues:</p>
<ol type="1">
<li>If there are many large files, copying them into the context can slow down your builds.</li>
<li>If you’re <code>COPY</code>ing whole directories, you might copy files you didn’t mean to, which can mean larger images or even leaking secret information.</li>
<li>Files you don’t care about may invalidate the cache.</li>
</ol>
<p>The solution is to create a <code>.dockerignore</code> file, listing files you don’t want to be included in the context and therefore the final Docker image. For example:</p>
<pre><code>Dockerfile
.dockerignore
venv/
**/__pycache__</code></pre>
<h3 id="references-36">References</h3>
<ul>
<li><a href="https://docs.docker.com/engine/reference/builder/#dockerignore-file"><code>.dockerignore</code> reference</a> (docs.docker.com)</li>
</ul>
<h2 id="git-dockerignore">Add <code>.git</code> to <code>.dockerignore</code> (and some alternatives when you can’t)</h2>
<p>If you’re using Git, a useful entry to add to your <code>.dockerignore</code> is the <code>.git</code> directory: by default it includes the full history of your repository, which can be quite large.</p>
<p>In some cases, this may not be possible.</p>
<p>If you’re using a tool like <code>setuptools-scm</code> or <code>versioneer</code> to set your Python application’s version using Git tags. In this case you can try one of the following options to minimize the size of the <code>.git</code> directory:</p>
<ul>
<li>Minimize the size of the <code>.git</code> directory by doing a “shallow” clone, e.g. <code>git clone --depth=50 yourrepo.git</code>, where you only download the last N revisions instead of the full history. Many CI services (GitHub Actions, GitLab CI) already do this by default. The downside is that tags that are in older revisions outside the shallowly clone history won’t show up, which can break the auto-versioning tools mentioned above.</li>
<li>Use <code>git clone --filter=blob:none yourrepo.git</code>. This only downloads the contents of history when you need access to it. That means tags will all be visible, but the <code>.git</code> folder will be much smaller unless you explicitly check out lots of tags and branches.</li>
</ul>
<p>You can also rely on a <a href="#multi-stage">multi-stage Docker build</a> to ensure the <code>.git</code> directory doesn’t make it into the runtime image, at least.</p>
<p>If your application’s runtime logic relies on <code>.git</code> to figure out its version, you can make this logic conditional, with a fallback to environment variables which can then be <a href="#identifiable">provided by the Docker image</a>.</p>
<h3 id="references-37">References</h3>
<ul>
<li><a href="https://git-scm.com/docs/git-clone"><code>git clone</code> documentation</a> (git-scm.com)</li>
</ul>
<h2 id="chown">Avoid extra chowns</h2>
<p>Any time you modify a file in any way in the <code>Dockerfile</code>, a whole new copy is stored in the next layer. Recursive <code>chown</code>s can therefore result in very large images, since you’re duplicating every file you change.</p>
<p>Therefore, instead of doing:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true"></a><span class="kw">COPY</span> code .</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true"></a><span class="kw">RUN</span> chown -R youruser code</span></code></pre></div>
<p>You should instead do:</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true"></a><span class="kw">COPY</span> --chown=youruser code .</span></code></pre></div>
<p>This will do the <code>chown</code> as part of the copy, ensuring only one copy of the files is kept.</p>
<h3 id="references-38">References</h3>
<ul>
<li><a href="https://docs.docker.com/engine/reference/builder/#copy"><code>Dockerfile</code> <code>COPY</code> reference</a> (docs.docker.com)</li>
</ul>
<h2 id="system-packages-clean">Don’t install unnecessary system packages, and clean up when you’re done</h2>
<p>When you install system packages, whether DEB or RPM, the package manager will typically keep a copy of the original package around, and also store the package listing from the package index. This wastes space.</p>
<p>You can’t delete these unneeded files in a separate <code>RUN</code> because Docker layers are always additive. So the solution is to have a single shell script that installs the packages, and then cleans up unnecessary files.</p>
<p>Additionally, when you install a package, non-essential but recommended dependencies may get installed, wasting space. Instead, you want to install only the minimal necessary dependencies to ensure smaller images.</p>
<p>For Debian/Ubuntu systems, the following shell script will do the trick:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true"></a></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true"></a><span class="co"># Tell apt-get we&#39;re never going to be able to give manual</span></span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true"></a><span class="co"># feedback:</span></span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true"></a><span class="bu">export</span> <span class="va">DEBIAN_FRONTEND=</span>noninteractive</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true"></a></span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true"></a><span class="co"># Update the package listing, so we know what package exist:</span></span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true"></a><span class="ex">apt-get</span> update</span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true"></a></span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true"></a><span class="co"># Install security updates:</span></span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true"></a><span class="ex">apt-get</span> -y upgrade</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true"></a></span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true"></a><span class="co"># Install a new package, without unnecessary recommended packages:</span></span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true"></a><span class="ex">apt-get</span> -y install --no-install-recommends YOUR_PACKAGE_LIST_GOES_HERE</span>
<span id="cb97-16"><a href="#cb97-16" aria-hidden="true"></a></span>
<span id="cb97-17"><a href="#cb97-17" aria-hidden="true"></a><span class="co"># Delete cached files we don&#39;t need anymore:</span></span>
<span id="cb97-18"><a href="#cb97-18" aria-hidden="true"></a><span class="ex">apt-get</span> clean</span>
<span id="cb97-19"><a href="#cb97-19" aria-hidden="true"></a><span class="fu">rm</span> -rf /var/lib/apt/lists/*</span></code></pre></div>
<p>In practice, modern Debian base images (both the official Debian and official Ubuntu images) will actually do at least part of the clean-up step automatically themselves, so you can skip that if you want, but can’t hurt to make sure.</p>
<p>For RPM-based systems like RHEL:</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true"></a></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true"></a><span class="co"># Install security updates, bug fixes and enhancements only.</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true"></a><span class="co"># --nodocs means documentation isn&#39;t installed, leading to a slightly smaller image.</span></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true"></a><span class="ex">dnf</span> -y --nodocs upgrade-minimal</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true"></a></span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true"></a><span class="co"># Install a new package, without unnecessary recommended packages:</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true"></a><span class="ex">dnf</span> -y --nodocs install --setopt=install_weak_deps=False YOUR_PACKAGE_LIST</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true"></a></span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true"></a><span class="co"># Delete cached files we don&#39;t need anymore:</span></span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true"></a><span class="ex">dnf</span> clean all</span></code></pre></div>
<h3 id="references-39">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/system-packages-docker/">Installing system packages in Docker with minimal bloat</a> (pythonspeed.com)</li>
<li><a href="https://www.debian.org/doc/user-manuals#apt-guide">APT User’s Guide</a> (debian.org)</li>
<li><a href="https://dnf.readthedocs.io/en/latest/index.html">DNF Documentation</a> (dnf.readthedocs.io)</li>
</ul>
<h2 id="smaller-pip">Disable pip caching</h2>
<p>By default <code>pip</code> keeps a copy of downloaded packages. This wastes space.</p>
<p>To fix this, run <code>pip</code> with caching disabled:</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true"></a><span class="kw">RUN</span> pip install --no-cache-dir flask</span></code></pre></div>
<h2 id="package-cache-buildkit">Optional: Caching installed packages using BuildKit or Podman</h2>
<p>By default <code>pip</code> caches downloaded packages so that new virtualenvs won’t require you to redownload everything. With classic Docker you are forced to redownload the same packages every time <code>requirements.txt</code> changed.</p>
<p>However, BuildKit and newer versions of Podman allow you to cache a directory outside of your image and across builds, which allows you to get a similar set of benefits. This level of caching is distinct from Docker’s layer caching. If you change <code>requirements.txt</code>, <code>pip</code> will still need to be rerun when you rebuild your Docker image, but at least it won’t have to download everything from scratch.</p>
<p>If we’re using this feature we do not need to use best practices like <code>pip install --no-cache</code>: saving downloaded packages is actually desirable because they’re cached outside the image. And since the official Debian Docker base image actually deletes downloaded packages and archive indexes automatically, we want to disable that feature too because we’re making sure to cache outside the image.</p>
<p>Here’s how to use this form of caching:</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true"></a><span class="co"># syntax = docker/dockerfile:1.4</span></span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true"></a></span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true"></a><span class="co"># Disable auto-cleanup after install:</span></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true"></a><span class="kw">RUN</span> rm /etc/apt/apt.conf.d/docker-clean</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true"></a><span class="co"># Cache downloaded packages across runs:</span></span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true"></a><span class="kw">RUN</span> --mount=type=cache,target=/var/cache/apt,id=apt \</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true"></a>  apt-get update &amp;&amp; apt-get -y upgrade</span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true"></a></span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true"></a><span class="co"># Cache downloaded packages across runs:</span></span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true"></a><span class="kw">RUN</span> --mount=type=cache,target=/root/.cache,id=pip \</span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true"></a>  pip install -r requirements.txt</span></code></pre></div>
<p>If you rebuild this (or another!) image on the same machine and have to redo the <code>apt-get</code> or <code>pip install</code>, the already downloaded packages will be available to the installer and won’t need to be redownloaded.</p>
<p>Make sure to enable BuildKit with <code>export DOCKER_BUILDKIT=1</code>.</p>
<p>For the <code>pip</code> packages I’m caching the <code>~/.cache</code> directory, since that is also where Pipenv and Poetry will store their files; <code>pip</code> uses <code>~/.cache/pip</code> by default. You’ll want to use the absolute path version of <code>~/.cache</code>, e.g. <code>/home/youruser/.cache</code>.</p>
<h3 id="references-40">References</h3>
<ul>
<li><a href="https://hub.docker.com/r/docker/dockerfile/"><code>Dockerfile</code> BuildKit extensions</a> (hub.docker.com)</li>
<li><a href="https://github.com/debuerreotype/debuerreotype/blob/master/scripts/debuerreotype-minimizing-config">Debian base image apt config scripts</a> (github.com)</li>
<li><a href="https://pythonspeed.com/articles/docker-cache-pip-downloads/">Speed up pip downloads in Docker with BuildKit’s new caching</a> (pythonspeed.com)</li>
</ul>
<h2 id="unnecessary-files">Optional: Remove files you don’t need</h2>
<p>Your Docker image may end up with files in it that you don’t need, and whose existence you can’t prevent with other techniques. You have a number of options to get rid of these extraneous files, if they’re taking up too much space:</p>
<ul>
<li><a href="#multi-stage">Multi-stage builds</a>; see the relevant chapter of the handbook.</li>
<li>The <code>docker-squash</code> tool allows you to merge multiple layers into one.</li>
<li>The <code>docker-slim</code> tool uses runtime instrumentation to figure out which files your container actually uses (probably a tiny subset!) and creates a new image with only those files.</li>
</ul>
<h3 id="references-41">References</h3>
<ul>
<li><a href="https://github.com/goldmann/docker-squash"><code>docker-squash</code></a> (github.com)</li>
<li><a href="https://github.com/docker-slim/docker-slim"><code>docker-slim</code></a> (github.com)</li>
</ul>
<h1 id="best-practices-application-and-tool-specific">Best practices: Application and tool-specific</h1>
<h2 id="using-a-virtualenv-in-your-dockerfile">Using a virtualenv in your <code>Dockerfile</code></h2>
<p>The <code>activate</code> script included in the virtualenv isn’t very usable from a <code>Dockerfile</code>, because each <code>RUN</code> is a separate shell session. Instead, to activate a virtualenv, you just need to set two environment variables:</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true"></a><span class="kw">ENV</span> VIRTUAL_ENV=/opt/venv</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true"></a><span class="kw">RUN</span> python -m venv $VIRTUAL_ENV</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true"></a><span class="kw">ENV</span> PATH=<span class="st">&quot;$VIRTUAL_ENV/bin:$PATH&quot;</span></span></code></pre></div>
<h3 id="references-42">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/activate-virtualenv-dockerfile/">Elegantly activating a virtualenv in a Dockerfile</a> (pythonspeed.com)</li>
</ul>
<h2 id="dont-run-database-upgrades-on-startup">Don’t run database upgrades on startup</h2>
<p>Your application might require database schema upgrades. You should not, however, run those schema upgrades as part of your container’s startup:</p>
<ol type="1">
<li>Most schema management systems will break if you do the same schema upgrade concurrently, and it’s common to run multiple copies of the same container.</li>
<li>It will encourage you to tightly couple your code to the database schema, making schema rollbacks difficult or impossible.</li>
</ol>
<p>Instead, you should decouple the two. The usual solution for this is to make your schema changes purely additive, e.g. adding columns but not deleting them:</p>
<ol type="1">
<li>Migrate from schema S to schema S+1, with only additive changes.</li>
<li>Over time upgrade some of your processes from application version V to V+1.</li>
<li>Eventually everything is on V+1, and you don’t ever expect to rollback to V.</li>
<li>Finally, migrate from schema S+1 to S+2, and now you can do destructive schema changes to anything that V+1 no longer uses.</li>
</ol>
<h3 id="references-43">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/schema-migrations-server-startup/">Decoupling database migrations from server startup: why and how</a> (pythonspeed.com)</li>
<li><a href="https://flywaydb.org/">Flyway</a> (flywaydb.org) does support concurrent schema upgrades, unlike most tools</li>
<li><a href="https://www.martinfowler.com/articles/evodb.html">Evolutionary Database Design</a> (martinfowler.com)</li>
</ul>
<h2 id="slow-queries">Make sure slow queries don’t break health checks</h2>
<p>If you’ve implemented health checks for your server, the runtime environment is occasionally sending queries to your server to see if it’s still alive. An HTTP server will get HTTP queries, for example.</p>
<p>Now, imagine you have a single-threaded HTTP server that can only handle one query at a time. And this server sometimes takes a long time to answer queries, and in particular it’s blocking while handling that query. Consider the following timeline:</p>
<ol type="1">
<li>A slow query is sent to the server. The server starts processing, but doesn’t respond yet.</li>
<li>The runtime environment sends a liveness check to server, and gets no response because slow query is still running.</li>
<li>The runtime environment sends another liveness check.</li>
<li>The runtime environment sends yet another liveness check.</li>
<li>The runtime environment decides the server is dead and kills it before it can finish responding to the slow query.</li>
</ol>
<p>If you expect slow queries, you should configure your application with enough concurrency that it can handle health check liveness queries. For typical WSGI web applications this can be done by running multiple threads, or multiple processes, depending on the application configuration.</p>
<h2 id="enable-running-other-commands-via-the-command-line">Enable running other commands via the command-line</h2>
<p>The combination of <code>ENTRYPOINT</code> and <code>CMD</code> allows you to have default command-line arguments for your application, and allows users to run your container with different command-line options.</p>
<p>In some cases, however, you never expect the user to pass in any command-line options to the entrypoint. Instead, you want them to be able to run a <em>different</em> program when they give command-line options. This can be useful for debugging, for example.</p>
<p>Thus by default the official <code>python</code> image runs Python:</p>
<pre><code>$ docker run -it python:3.10-slim-bullseye
Python 3.8.3 (default, Jun  9 2020, 17:49:41) 
[GCC 8.3.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;</code></pre>
<p>But you can pass it other commands instead, in this case <code>bash</code>:</p>
<pre><code>$ docker run -it python:3.10-slim-bullseye \
    bash -c &#39;echo hello, I am $(whoami)&#39;
hello, I am root</code></pre>
<p>You can do this with the following combination of <code>ENTRYPOINT</code> and <code>CMD</code> in your <code>Dockerfile</code>:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> []</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true"></a><span class="kw">CMD</span> [<span class="st">&quot;/app/entrypoint.sh&quot;</span>]</span></code></pre></div>
<h3 id="references-44">References</h3>
<ul>
<li><a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>ENTRYPOINT</code> reference</a> (docs.docker.com)</li>
<li><a href="https://docs.docker.com/engine/reference/builder/#cmd"><code>CMD</code> reference</a> (docs.docker.com)</li>
</ul>
<h2 id="gunicorn">Configure the Gunicorn web server correctly</h2>
<p>In addition to the need to support multiple threads (see above), Gunicorn uses <code>/tmp</code> as a default location for its internal heartbeat system for communicating with workers. On Docker that is an on-disk filesystem, which means the heartbeat system can be slow, making Gunicorn unresponsive.</p>
<p>You should therefore use <code>/dev/shm</code>, an in-memory filesystem, as the location for the heartbeat file.</p>
<p>A working configuration where logs also go to stdout might therefore look like this:</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true"></a><span class="bu">exec</span> gunicorn --worker-tmp-dir /dev/shm --workers=2 <span class="kw">\</span></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true"></a>              <span class="ex">--threads</span>=4 --worker-class gthread <span class="kw">\</span></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true"></a>              <span class="ex">--log-file</span>=- --bind 0.0.0.0:8000 yourmodule:yourapp</span></code></pre></div>
<h3 id="references-45">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/gunicorn-in-docker/">Configuring Gunicorn for Docker</a> (pythonspeed.com)</li>
<li><a href="https://docs.gunicorn.org/en/stable/index.html">Gunicorn documentation</a> (docs.gunicorn.org)</li>
</ul>
<h2 id="uwsgi">Configure the uWSGI web server correctly</h2>
<p>Configuring uWSGI is complex.</p>
<p>In addition to the need to support multiple threads and logging to <code>stdout</code> (see above), uWSGI has some oddities. Just a couple worth mentioning:</p>
<ol type="1">
<li>By default it will <code>fork()</code> workers without <code>exec()</code>ing a new Python process, which supposedly saves memory but actually just makes your Python program much more likely to crash if you use the wrong library.</li>
<li>The default behavior for environment dictionaries doesn’t match the WSGI standard.</li>
</ol>
<p>You can fix these issues in the <code>uwsgi.ini</code> file:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode default"><code class="sourceCode default"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true"></a>[uwsgi]</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true"></a>lazy-apps = true</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true"></a>wsgi-env-behaviour = holy</span></code></pre></div>
<p>The Tech at Bloomberg article referenced below on uWSGI in production doesn’t even mention these two, but does mention many other details you need to configure to get uWSGI working correctly.</p>
<p>While it’s true that uWSGI is fast, in most web applications the bottleneck is the database, not the web server. And personally I feel the <code>fork()</code>-without-<code>exec()</code> design choice shows such bad judgment that I don’t trust uWSGI, but that’s just me; it seems like it works for some people with enough configuration tweaks.</p>
<p>Technically Gunicorn does an <code>exec()</code> without <code>fork()</code> too, but it does it much earlier in the process, before you load your code, so it’s less likely to be an issue. Other WSGI containers may be better than either.</p>
<h3 id="references-46">References</h3>
<ul>
<li><a href="https://engineering.ticketea.com/uwsgi-preforking-lazy-apps/">uWSGI Preforking and Lazy Apps</a> (engineering.ticketea.com)</li>
<li><a href="https://uwsgi-docs.readthedocs.io/en/latest/articles/WSGIEnvBehaviour.html">uWSGI env behaviour policies</a> (uwsgi-docs.readthedocs.io)</li>
<li><a href="https://www.techatbloomberg.com/blog/configuring-uwsgi-production-deployment/">Configuring uWSGI for Production Deployment</a> (techatbloomberg.com)</li>
</ul>
<h2 id="heroku">Respect the <code>PORT</code> environment variable on Heroku and Google Cloud Run</h2>
<p>If you’re deploying your image on Heroku or Google Cloud Run, you will be expected to have your server listen on a port number specified in the <code>PORT</code> environment variable.</p>
<p>Note that just like binding to <code>0.0.0.0</code>, the port to listen to is specific to your server. Gunicorn, uWSGI, etc. will all have different command line or configuration file options–read the relevant documentation for your server.</p>
<p>As an example, you’ll probably want an <code>entrypoint.sh</code>. The <code>${PORT:-8080}</code> means that if no <code>$PORT</code> environment variable was set, a default value of <code>8080</code> will be used:</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true"></a><span class="bu">exec</span> python -m http.server <span class="va">${PORT:-</span>8080<span class="va">}</span></span></code></pre></div>
<p>The <code>Dockerfile</code> will then use this entrypoint:</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true"></a><span class="kw">COPY</span> entrypoint.sh .</span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;./entrypoint.sh&quot;</span>]</span></code></pre></div>
<p>Heroku also requires you to run as a non-root user.</p>
<h3 id="references-47">References</h3>
<ul>
<li><a href="https://devcenter.heroku.com/articles/container-registry-and-runtime#dockerfile-commands-and-runtime">Heroku’s Docker image requirements</a> (devcenter.heroku.com)</li>
<li><a href="https://cloud.google.com/run/docs/reference/container-contract">Google Cloud Run’s Docker image requirements</a> (cloud.google.com)</li>
</ul>
<h1 id="conda">Best practices: Conda</h1>
<h2 id="using-a-conda-environment-in-your-dockerfile">Using a Conda environment in your <code>Dockerfile</code></h2>
<p>Activating a Conda environment is a much more complex task than activating a virtualenv, because environment variables won’t work.</p>
<h3 id="activating-with-conda-run">Activating with <code>conda run</code></h3>
<p>One approach is to use <code>conda run</code>, which allows you to run a command inside a specified environment:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true"></a><span class="kw">FROM</span> continuumio/miniconda3</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true"></a></span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true"></a></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true"></a><span class="co"># Create the environment:</span></span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true"></a><span class="kw">COPY</span> environment.yml .</span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true"></a><span class="co"># We give it a custom name, &quot;myenv&quot;:</span></span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true"></a><span class="kw">RUN</span> conda env create -n myenv</span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true"></a></span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true"></a><span class="co"># Make RUN commands use the new environment:</span></span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true"></a><span class="kw">SHELL</span> [<span class="st">&quot;conda&quot;</span>, <span class="st">&quot;run&quot;</span>, <span class="st">&quot;--no-capture-output&quot;</span>, <span class="st">&quot;-n&quot;</span>, <span class="st">&quot;myenv&quot;</span>, <span class="st">&quot;/bin/bash&quot;</span>, <span class="st">&quot;-c&quot;</span>]</span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true"></a></span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true"></a><span class="co"># ... the rest of the build ...</span></span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true"></a></span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true"></a><span class="co"># The code to run when container is started:</span></span>
<span id="cb109-16"><a href="#cb109-16" aria-hidden="true"></a><span class="kw">COPY</span> run.py .</span>
<span id="cb109-17"><a href="#cb109-17" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;conda&quot;</span>, <span class="st">&quot;run&quot;</span>, <span class="st">&quot;--no-capture-output&quot;</span>, <span class="st">&quot;-n&quot;</span>, <span class="st">&quot;myenv&quot;</span>, <span class="st">&quot;python&quot;</span>, <span class="st">&quot;run.py&quot;</span>]</span></code></pre></div>
<p>The <code>--no-capture-output</code> ensures the stdout and stderr output from Python isn’t hidden by <code>conda run</code>.</p>
<h3 id="activating-with-shell-startup">Activating with shell startup</h3>
<p>Another approach takes advantage of the fact that <code>continuumio/miniconda3</code> configures <code>bash</code> to load the Conda startup shell scripts, and activate the environment in the entrypoint.</p>
<p>There’s one tricky point here: typically I would recommend using <a href="#bash">bash strict mode</a>. However, some Conda activation scripts break with this mode is enabled! So what we have to do is disable strict mode while activating the script.</p>
<p>We have an <code>entrypoint.sh</code> to run the program:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true"></a><span class="co">#!/bin/bash --login</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true"></a><span class="co"># The --login ensures the bash configuration is loaded,</span></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true"></a><span class="co"># enabling Conda.</span></span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true"></a></span>
<span id="cb110-5"><a href="#cb110-5" aria-hidden="true"></a><span class="co"># Enable strict mode.</span></span>
<span id="cb110-6"><a href="#cb110-6" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb110-7"><a href="#cb110-7" aria-hidden="true"></a><span class="co"># ... Run whatever additional commands ...</span></span>
<span id="cb110-8"><a href="#cb110-8" aria-hidden="true"></a></span>
<span id="cb110-9"><a href="#cb110-9" aria-hidden="true"></a><span class="co"># Temporarily disable strict mode and activate conda:</span></span>
<span id="cb110-10"><a href="#cb110-10" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">+euo</span> pipefail</span>
<span id="cb110-11"><a href="#cb110-11" aria-hidden="true"></a><span class="ex">conda</span> activate myenv</span>
<span id="cb110-12"><a href="#cb110-12" aria-hidden="true"></a></span>
<span id="cb110-13"><a href="#cb110-13" aria-hidden="true"></a><span class="co"># Re-enable strict mode:</span></span>
<span id="cb110-14"><a href="#cb110-14" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb110-15"><a href="#cb110-15" aria-hidden="true"></a></span>
<span id="cb110-16"><a href="#cb110-16" aria-hidden="true"></a><span class="co"># Run the program:</span></span>
<span id="cb110-17"><a href="#cb110-17" aria-hidden="true"></a><span class="bu">exec</span> python run.py</span></code></pre></div>
<p>And here’s the <code>Dockerfile</code>:</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true"></a><span class="kw">FROM</span> continuumio/miniconda3</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true"></a></span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true"></a></span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true"></a><span class="co"># Create the environment:</span></span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true"></a><span class="kw">COPY</span> environment.yml .</span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true"></a><span class="co"># We give it a custom name, &quot;myenv&quot;:</span></span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true"></a><span class="kw">RUN</span> conda env create -n myenv</span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true"></a></span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true"></a><span class="co"># Make RUN commands use the new environment:</span></span>
<span id="cb111-11"><a href="#cb111-11" aria-hidden="true"></a><span class="kw">RUN</span> echo <span class="st">&quot;conda activate myenv&quot;</span> &gt;&gt; ~/.bashrc</span>
<span id="cb111-12"><a href="#cb111-12" aria-hidden="true"></a><span class="kw">SHELL</span> [<span class="st">&quot;/bin/bash&quot;</span>, <span class="st">&quot;--login&quot;</span>, <span class="st">&quot;-c&quot;</span>]</span>
<span id="cb111-13"><a href="#cb111-13" aria-hidden="true"></a></span>
<span id="cb111-14"><a href="#cb111-14" aria-hidden="true"></a><span class="co"># ... the rest of the build ...</span></span>
<span id="cb111-15"><a href="#cb111-15" aria-hidden="true"></a></span>
<span id="cb111-16"><a href="#cb111-16" aria-hidden="true"></a><span class="co"># The code to run when container is started:</span></span>
<span id="cb111-17"><a href="#cb111-17" aria-hidden="true"></a><span class="kw">COPY</span> run.py entrypoint.sh ./</span>
<span id="cb111-18"><a href="#cb111-18" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;./entrypoint.sh&quot;</span>]</span></code></pre></div>
<h3 id="references-48">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/activate-conda-dockerfile/">Activating a Conda environment in your Dockerfile</a> (pythonspeed.com)</li>
</ul>
<h2 id="conda-environments-require-activation">Conda environments require activation</h2>
<p>You should not simply call binaries in the Conda <code>bin/</code> directory without activating the environment. This will work fine for virtualenvs, but might fail for Conda in certain cases.</p>
<p>This is because Conda packages can include activation scripts that are necessary for the packages to work correctly. You therefore need to make sure those activation scripts get called, which is part of what Conda environment activation does.</p>
<h3 id="references-49">References</h3>
<ul>
<li><a href="https://docs.conda.io/projects/conda-build/en/latest/resources/activate-scripts.html">Activate scripts in Conda packages</a></li>
</ul>
<h2 id="reproducible-builds-with-conda-lock">Reproducible builds with <code>conda-lock</code></h2>
<p>In order to get reproducible builds, you will want to transitively pin your dependencies. For example, the following <code>environment.yml</code> will install different packages each time:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true"></a><span class="fu">name</span><span class="kw">:</span><span class="at"> example</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true"></a><span class="fu">channels</span><span class="kw">:</span></span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true"></a><span class="at">  </span><span class="kw">-</span><span class="at"> conda-forge</span></span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true"></a><span class="fu">dependencies</span><span class="kw">:</span></span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true"></a><span class="at">  </span><span class="kw">-</span><span class="at"> python=3.8</span></span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true"></a><span class="at">  </span><span class="kw">-</span><span class="at"> numpy</span></span></code></pre></div>
<p>Even if you pinned specific packages, that won’t necessarily install the same dependencies, you need transitive pinning.</p>
<p><code>conda-lock</code> is a tool that lets you pin packages transitively, creating what’s known as a spec list, or lockfile, a list of packages to download. The additional benefit of a spec list is that you can skip the slow “Solving dependencies” stage you get when you install an <code>environment.yml</code>.</p>
<p>There are two steps. First, you pin the dependencies, which you can do on any computer with any operating system (Windows or macOS work too). Note that you can also install <code>conda-lock</code> using <code>pip</code>.</p>
<pre><code>$ conda install -c conda-forge conda-lock
$ conda-lock lock -f environment.yml -p linux-64</code></pre>
<p>This will generate a <code>conda-lock.yml</code> file. Any time you want to update your dependencies you’ll need to regenerate this file by rerunning <code>conda-lock</code>, and it will get the latest version of dependencies in <code>environment.yml</code>.</p>
<p>You can then use this file to create a Conda environment in your Docker image, using a slightly different method than what you’d use with an <code>environment.yml</code>:</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true"></a><span class="kw">FROM</span> continuumio/miniconda3</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true"></a></span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true"></a><span class="kw">COPY</span> conda-lock.yml .</span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true"></a><span class="kw">RUN</span> conda install -c conda-forge conda-lock</span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true"></a><span class="co"># Create environment called &quot;yourenv&quot;:</span></span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true"></a><span class="kw">RUN</span> conda-lock install --name yourenv conda-lock.yml</span></code></pre></div>
<p>Newer versions of <code>conda-lock</code> also support locking <code>pip</code>-based dependencies from your <code>environment.yml</code>, so you can have a single lock file that encompasses both types of packages.</p>
<p>If you don’t want to install the <code>conda-lock</code> utility in the Docker image, you can create an alternative file, a <code>conda-linux-64.yml</code> file:</p>
<pre><code>$ conda-lock lock --kind=explicit -p linux-64</code></pre>
<p>You can then create an environment in your Docker image using <code>conda create</code>:</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true"></a><span class="kw">FROM</span> continuumio/miniconda3</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true"></a></span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true"></a><span class="kw">COPY</span> conda-linux-64.lock .</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true"></a><span class="co"># Create environment called &quot;yourenv&quot;:</span></span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true"></a><span class="kw">RUN</span> conda create --name yourenv --file conda-linux-64.lock</span></code></pre></div>
<p>This style of file cannot support <code>pip</code> dependencies, however.</p>
<h3 id="references-50">References</h3>
<ul>
<li><a href="github.com/conda-incubator/conda-lock/"><code>conda-lock</code></a> (github.com)</li>
<li><a href="https://pythonspeed.com/articles/conda-dependency-management/">Reproducible and upgradable Conda environments: dependency management with conda-lock</a> (pythonspeed.com)</li>
</ul>
<h2 id="make-conda-images-smaller-with-conda-clean">Make Conda images smaller with <code>conda clean</code></h2>
<p>By default, Conda will cache a variety of files: index files, downloaded packages, and so on. If you don’t anticipate doing any further installs, you can delete all these files using <code>conda run</code> to save some space.</p>
<p>Make sure to do this in the same <code>RUN</code> command where you install the packages, to ensure the files aren’t saved in a previous layer.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true"></a><span class="kw">FROM</span> continuumio/miniconda3</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true"></a></span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true"></a><span class="kw">COPY</span> environment.yml .</span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true"></a><span class="kw">RUN</span> conda env create -n myenv &amp;&amp; \</span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true"></a>    conda clean -afy</span></code></pre></div>
<h3 id="references-51">References</h3>
<ul>
<li><a href="https://docs.conda.io/projects/conda/en/latest/commands/clean.html"><code>conda clean</code> documentation</a> (docs.conda.io)</li>
</ul>
<h2 id="make-conda-images-smaller-by-using-openblas">Make Conda images smaller by using OpenBLAS</h2>
<p>If you’re using NumPy, or packages like Pandas that depends on NumPy, you need to choose which BLAS linear algebra library to use. The two choices are MKL, which is often faster, and OpenBLAS, which uses much less disk space.</p>
<p>Switching to OpenBLAS depends on where you’re installing packages from:</p>
<ul>
<li>The packages you install with <code>pip</code> use OpenBLAS.</li>
<li>If you’re installing packages from the Conda-Forge channel, OpenBLAS is the default, so you don’t need to take any further action to get smaller images.</li>
<li>If you’re using the default Anaconda packages, MKL is the default, and if you want OpenBLAS you’ll want to add <code>nomkl</code> to the packages you’re installing. This will shave something like 700MB off your Docker image!</li>
</ul>
<div class="sourceCode" id="cb118"><pre class="sourceCode yaml"><code class="sourceCode yaml"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true"></a><span class="fu">name</span><span class="kw">:</span><span class="at"> example</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true"></a><span class="fu">dependencies</span><span class="kw">:</span></span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true"></a><span class="at">  </span><span class="kw">-</span><span class="at"> python=3.8</span></span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true"></a><span class="at">  </span><span class="kw">-</span><span class="at"> numpy</span></span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true"></a><span class="at">  </span><span class="kw">-</span><span class="at"> nomkl</span></span></code></pre></div>
<h3 id="references-52">References</h3>
<ul>
<li><a href="https://docs.anaconda.com/mkl-optimizations/#uninstalling-mkl">Omitting <code>mkl</code> in Anaconda</a> (docs.anaconda.com)</li>
<li><a href="https://jcristharif.com/conda-docker-tips.html">Smaller Docker images with Conda</a> (jcristharif.com)</li>
</ul>
<h2 id="even-smaller-conda-images-with-conda-pack-and-multi-stage-builds">Even smaller Conda images with <code>conda-pack</code> and multi-stage builds</h2>
<p>In addition to the Conda environment you create, by default your Conda-based Docker image will ship with the base environment, including a full install of Python. By using <code>conda-pack</code>, a tool that lets you convert a Conda environment into a standalone directory, you can drop that extra environment and any other unneeded files from the final runtime image.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true"></a><span class="co"># The build-stage image:</span></span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true"></a><span class="kw">FROM</span> continuumio/miniconda3 AS build</span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true"></a></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true"></a><span class="co"># Install the package as normal:</span></span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true"></a><span class="kw">COPY</span> environment.yml .</span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true"></a><span class="kw">RUN</span> conda env create -n myenv</span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true"></a></span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true"></a><span class="co"># Install conda-pack:</span></span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true"></a><span class="kw">RUN</span> conda install -c conda-forge conda-pack</span>
<span id="cb119-10"><a href="#cb119-10" aria-hidden="true"></a></span>
<span id="cb119-11"><a href="#cb119-11" aria-hidden="true"></a><span class="co"># Use conda-pack to create a standalone enviornment</span></span>
<span id="cb119-12"><a href="#cb119-12" aria-hidden="true"></a><span class="co"># in /venv:</span></span>
<span id="cb119-13"><a href="#cb119-13" aria-hidden="true"></a><span class="kw">RUN</span> conda-pack -n myenv -o /tmp/env.tar &amp;&amp; \</span>
<span id="cb119-14"><a href="#cb119-14" aria-hidden="true"></a>  mkdir /venv &amp;&amp; cd /venv &amp;&amp; tar xf /tmp/env.tar &amp;&amp; \</span>
<span id="cb119-15"><a href="#cb119-15" aria-hidden="true"></a>  rm /tmp/env.tar</span>
<span id="cb119-16"><a href="#cb119-16" aria-hidden="true"></a></span>
<span id="cb119-17"><a href="#cb119-17" aria-hidden="true"></a><span class="co"># We&#39;ve put venv in same path it&#39;ll be in final image,</span></span>
<span id="cb119-18"><a href="#cb119-18" aria-hidden="true"></a><span class="co"># so now fix up paths:</span></span>
<span id="cb119-19"><a href="#cb119-19" aria-hidden="true"></a><span class="kw">RUN</span> /venv/bin/conda-unpack</span>
<span id="cb119-20"><a href="#cb119-20" aria-hidden="true"></a></span>
<span id="cb119-21"><a href="#cb119-21" aria-hidden="true"></a></span>
<span id="cb119-22"><a href="#cb119-22" aria-hidden="true"></a><span class="co"># The runtime-stage image; we can use Debian as the</span></span>
<span id="cb119-23"><a href="#cb119-23" aria-hidden="true"></a><span class="co"># base image since the Conda env also includes Python</span></span>
<span id="cb119-24"><a href="#cb119-24" aria-hidden="true"></a><span class="co"># for us.</span></span>
<span id="cb119-25"><a href="#cb119-25" aria-hidden="true"></a><span class="kw">FROM</span> debian:bullseye AS runtime</span>
<span id="cb119-26"><a href="#cb119-26" aria-hidden="true"></a></span>
<span id="cb119-27"><a href="#cb119-27" aria-hidden="true"></a><span class="co"># Copy /venv from the previous stage:</span></span>
<span id="cb119-28"><a href="#cb119-28" aria-hidden="true"></a><span class="kw">COPY</span> --from=build /venv /venv</span>
<span id="cb119-29"><a href="#cb119-29" aria-hidden="true"></a></span>
<span id="cb119-30"><a href="#cb119-30" aria-hidden="true"></a><span class="co"># When image is run, run the code with the environment</span></span>
<span id="cb119-31"><a href="#cb119-31" aria-hidden="true"></a><span class="co"># activated:</span></span>
<span id="cb119-32"><a href="#cb119-32" aria-hidden="true"></a><span class="kw">SHELL</span> [<span class="st">&quot;/bin/bash&quot;</span>, <span class="st">&quot;-c&quot;</span>]</span>
<span id="cb119-33"><a href="#cb119-33" aria-hidden="true"></a><span class="kw">ENTRYPOINT</span> source /venv/bin/activate &amp;&amp; \</span>
<span id="cb119-34"><a href="#cb119-34" aria-hidden="true"></a>           python -c <span class="st">&quot;import numpy; print(&#39;success!&#39;)&quot;</span></span></code></pre></div>
<p><code>conda-pack</code> may have issues if you are installing many packages with <code>pip</code>.</p>
<h3 id="references-53">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/conda-docker-image-size/">Shrink your Conda Docker images with conda-pack</a> (pythonspeed.com)</li>
<li><a href="https://conda.github.io/conda-pack/"><code>conda-pack</code> documentation</a> (conda.github.io)</li>
</ul>
<h2 id="faster-installs-with-mamba">Faster installs with Mamba</h2>
<p>Mamba is a re-implementation of the Conda package manager that runs much faster. It also supports the same command-line options as Conda, so once you’ve installed it you just need to replace <code>conda</code> with <code>mamba</code>:</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true"></a><span class="kw">FROM</span> continuumio/miniconda3</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true"></a><span class="kw">RUN</span> conda install -c conda-forge mamba</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true"></a><span class="co"># Now proceed as normal, just using mamba instead:</span></span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true"></a><span class="kw">RUN</span> mamba env create -n myenv</span></code></pre></div>
<h3 id="references-54">References</h3>
<ul>
<li><a href="https://github.com/mamba-org/mamba">Mamba</a> (github.com)</li>
</ul>
<h2 id="security-scans-for-conda-environments">Security scans for Conda environments</h2>
<p>Conda packages can include more than just Python packages, so if you want to scan your dependencies for security vulnerabilities you need a security scanner that understands this. One such tool is Jake.</p>
<p>Assuming you have an environment named <code>myenv</code> you create earlier in the <code>Dockerfile</code>, during the build, you can scan for vulnerabilities like so:</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true"></a><span class="co"># ... create a Conda env called &quot;myenv&quot; with your packages ...</span></span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true"></a></span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true"></a><span class="co"># Make virtualenv for Jake, run a security scan, and then clean up:</span></span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true"></a><span class="kw">RUN</span> python3 -m venv /tmp/venv-jake &amp;&amp; \</span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true"></a>    /tmp/venv-jake/bin/pip install jake &amp;&amp; \</span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true"></a>    conda run -n myenv conda list | (set -e &amp;&amp; \</span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true"></a>    /tmp/venv-jake/bin/jake ddt -c &amp;&amp; rm -rf /tmp/venv-jake)</span></code></pre></div>
<p>Note that Jake support for Conda-Forge may be limited.</p>
<h3 id="references-55">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/conda-security-scans/">Scanning your Conda environment for security vulnerabilities</a> (pythonspeed.com)</li>
<li><a href="https://github.com/sonatype-nexus-community/jake">Jake</a> (github.com)</li>
<li><a href="https://github.com/sonatype/ossindex-public/issues/27">Jake + Conda-Forge issue</a> (github.com)</li>
</ul>
<h1 id="pipenv">Best practices: Pipenv</h1>
<h2 id="install-pipenv-separately-from-your-application-code">Install Pipenv separately from your application code</h2>
<p>If you’re going to use Pipenv inside your Docker build, you need to install it. Since it has a variety of dependencies, you don’t want to install it into the same place as your code, in case the dependencies conflict.</p>
<p>As you’ll see in the next best practice, you can either:</p>
<ol type="1">
<li>Install Pipenv as a system package, and have Pipenv install dependencies in a virtualenv.</li>
<li>Export dependencies and install them using <code>pip</code>. If you follow this path, you could just uninstall Pipenv once you’ve done the export.</li>
</ol>
<h3 id="references-56">References</h3>
<ul>
<li><a href="https://pipenv.pypa.io/en/latest/"><code>pipenv</code> documentation</a> (pipenv.pypa.io)</li>
</ul>
<h2 id="installing-dependencies-inside-a-container">Installing dependencies inside a container</h2>
<p>There are two methods to install your dependencies inside your Docker build using Pipenv. The first method involves exporting the dependencies to a separate <code>requirements.txt</code> file, and then relying on <code>pip</code> to install them:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true"></a><span class="kw">RUN</span> pip install pipenv</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true"></a></span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true"></a><span class="kw">COPY</span> Pipfile* .</span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true"></a><span class="kw">RUN</span> pipenv requirements --hash &gt; /tmp/requirements.txt</span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true"></a></span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r /tmp/requirements.txt</span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true"></a></span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true"></a><span class="co"># ... install application code, set entrypoint ...</span></span></code></pre></div>
<p>The <code>--hash</code> option adds hashes to the <code>requirements.txt</code> file, which will be used to validate downloads, increasing security and robustness. You’ll need to use Pipenv 2022.4.8 or later for this command; previously you would do <code>pipenv lock --requirements</code>.</p>
<p>The other method involves creating a virtualenv and installing the packages there using Pipenv. Pipenv wants to only install in a virtualenv, and creating our own means it’s exactly where we want it:</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true"></a><span class="kw">RUN</span> pip install pipenv</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true"></a></span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true"></a><span class="co"># Create and activate virtualenv:</span></span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true"></a><span class="kw">RUN</span> python3 -m venv /venv</span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true"></a><span class="kw">ENV</span> PATH=/venv/bin:$PATH</span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true"></a><span class="kw">ENV</span> VIRTUAL_ENV=/venv</span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true"></a></span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true"></a><span class="kw">COPY</span> Pipfile.lock .</span>
<span id="cb123-10"><a href="#cb123-10" aria-hidden="true"></a></span>
<span id="cb123-11"><a href="#cb123-11" aria-hidden="true"></a><span class="co"># Install inside virtualenv:</span></span>
<span id="cb123-12"><a href="#cb123-12" aria-hidden="true"></a><span class="kw">RUN</span> pipenv install --keep-outdated --ignore-pipfile</span></code></pre></div>
<p>The two options to <code>pipenv install</code> allow us to only copy in the <code>Pipfile.lock</code>.</p>
<h3 id="references-57">References</h3>
<ul>
<li><a href="https://pipenv.pypa.io/en/latest/cli/#pipenv-lock"><code>pipenv lock</code></a> (pipenv.pypa.io)</li>
<li><a href="https://pipenv.pypa.io/en/latest/cli/#pipenv-install"><code>pipenv install</code></a> (pipenv.pypa.io)</li>
</ul>
<h1 id="poetry">Best practices: Poetry</h1>
<h2 id="install-poetry-separately-from-your-application-code">Install Poetry separately from your application code</h2>
<p>If you’re going to use Poetry inside your Docker build, you need to install it. Since it has a variety of dependencies, you don’t want to install it into the same place as your code, in case the dependencies conflict.</p>
<p>Some options:</p>
<ul>
<li>If you’re installing your code into a virtualenv, you can just install Poetry as a system package and it won’t conflict with the virtualenv’s libraries.</li>
<li>You can use Poetry’s installer to install it into its own isolated directory.</li>
</ul>
<p>Here’s how you do the latter:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true"></a></span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get install -y curl</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true"></a><span class="kw">ENV</span> POETRY_HOME=/tmp/poetry</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true"></a><span class="kw">RUN</span> curl -sSL https://install.python-poetry.org | python3 -</span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true"></a><span class="kw">ENV</span> PATH=$POETRY_HOME/bin:$PATH</span></code></pre></div>
<h3 id="references-58">References</h3>
<ul>
<li><a href="https://python-poetry.org/docs/#installation">Installing <code>poetry</code></a> (python-poetry.org)</li>
</ul>
<h2 id="installing-outside-of-poetrys-managed-virtualenvs">Installing outside of Poetry’s managed virtualenvs</h2>
<p>By default, Poetry will install code in a virtualenv that it creates and manages. If you want to install either in the normal system packages location, or in a virtualenv of your choosing, add this to your <code>Dockerfile</code> before installing any packages:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true"></a><span class="kw">RUN</span> poetry config virtualenvs.create false</span></code></pre></div>
<p>This will ensure <code>poetry install</code> doesn’t create its own virtual environment. Instead, it will install in either the normal system packages location, or the current activated virtualenv if there is one.</p>
<h3 id="references-59">References</h3>
<ul>
<li><a href="https://python-poetry.org/docs/configuration/#virtualenvscreate-boolean"><code>poetry's</code> <code>virtualenv.create</code></a> (python-poetry.org)</li>
</ul>
<h2 id="poetry-dev-depencies">Don’t install development dependencies (unless you want to)</h2>
<p>By default Poetry will install development dependencies, things like <code>flake8</code> that you’ve configured in <code>pyproject.toml</code> as only being required for development. To disable installing dev dependencies, use the <code>--no-dev</code> option.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true"></a><span class="kw">RUN</span> poetry install --no-dev</span></code></pre></div>
<h3 id="references-60">References</h3>
<ul>
<li><a href="https://python-poetry.org/docs/cli/#install"><code>poetry install</code> reference</a> (python-poetry.org)</li>
</ul>
<h2 id="poetry-dependencies-first">Speed up rebuilds by installing dependencies separately</h2>
<p>For Poetry, you can install dependencies separately to get better build caching by first doing <code>poetry install --no-root</code> to just install the dependencies:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true"></a></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true"></a><span class="co"># Install Poetry:</span></span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update &amp;&amp; apt-get install -y curl</span>
<span id="cb127-5"><a href="#cb127-5" aria-hidden="true"></a><span class="kw">ENV</span> POETRY_HOME=/tmp/poetry</span>
<span id="cb127-6"><a href="#cb127-6" aria-hidden="true"></a><span class="kw">RUN</span> curl -sSL https://install.python-poetry.org | python3 -</span>
<span id="cb127-7"><a href="#cb127-7" aria-hidden="true"></a><span class="kw">ENV</span> PATH=$POETRY_HOME/bin:$PATH</span>
<span id="cb127-8"><a href="#cb127-8" aria-hidden="true"></a></span>
<span id="cb127-9"><a href="#cb127-9" aria-hidden="true"></a><span class="co"># Don&#39;t create virtualenvs:</span></span>
<span id="cb127-10"><a href="#cb127-10" aria-hidden="true"></a><span class="kw">RUN</span> poetry config virtualenvs.create false</span>
<span id="cb127-11"><a href="#cb127-11" aria-hidden="true"></a></span>
<span id="cb127-12"><a href="#cb127-12" aria-hidden="true"></a><span class="co"># Copy in the config files:</span></span>
<span id="cb127-13"><a href="#cb127-13" aria-hidden="true"></a><span class="kw">WORKDIR</span> /myapp</span>
<span id="cb127-14"><a href="#cb127-14" aria-hidden="true"></a><span class="kw">COPY</span> pyproject.toml poetry.lock ./</span>
<span id="cb127-15"><a href="#cb127-15" aria-hidden="true"></a></span>
<span id="cb127-16"><a href="#cb127-16" aria-hidden="true"></a><span class="co"># Install only dependencies:</span></span>
<span id="cb127-17"><a href="#cb127-17" aria-hidden="true"></a><span class="kw">RUN</span> poetry install --no-dev --no-root</span>
<span id="cb127-18"><a href="#cb127-18" aria-hidden="true"></a></span>
<span id="cb127-19"><a href="#cb127-19" aria-hidden="true"></a><span class="co"># Copy in everything else and install app code:</span></span>
<span id="cb127-20"><a href="#cb127-20" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb127-21"><a href="#cb127-21" aria-hidden="true"></a><span class="kw">RUN</span> poetry install --no-dev</span></code></pre></div>
<p><strong>Important:</strong> When your application code is installed, it is <em>not</em> copied in, as would be the case when you install some other package like Flask, Django, or NumPy. Instead, Poetry creates a link to the directory where your code resides; in the example above, your code is expected to stay in <code>/myapp</code>. <strong>That means you can’t delete the original code even though you’ve installed it.</strong></p>
<p>If you do want to actually install the code in a way where the code is copied in, instead of using <code>poetry install</code> to install your code, do <code>poetry build</code> to create a wheel. You can then <code>pip install</code> the wheel—you can find it in the <code>dist/</code> directory of your project.</p>
<p>Or, you can use a so-called “PEP 517” install. Basically that means you install via <code>pip</code>, but <code>pip</code> then figures out from <code>pyproject.toml</code> how to get the information it needs from Poetry. As a side-effect, it also builds your application code as a wheel and installs it, so you can then delete the original directory.</p>
<p>If you created your <code>pyproject.toml</code> with a sufficiently new version of Poetry and <code>poetry new/init</code>, this will already be set up. Otherwise make sure <code>pyproject.toml</code> has the following section (see the Poetry docs linked below for details):</p>
<pre class="toml"><code>[build-system]
requires = [&quot;poetry_core&gt;=1.0.0&quot;]
build-backend = &quot;poetry.core.masonry.api&quot;</code></pre>
<p>Then, you can change the last part of the <code>Dockerfile</code> to install a different way:</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true"></a><span class="co"># ...</span></span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true"></a><span class="co"># Install Poetry and your dependencies as above.</span></span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true"></a><span class="co"># ...</span></span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true"></a></span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true"></a><span class="co"># Copy in everything else and install app code:</span></span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true"></a><span class="co"># Instead of `poetry install`:</span></span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true"></a><span class="kw">RUN</span> pip install .</span></code></pre></div>
<h3 id="references-61">References</h3>
<ul>
<li><a href="https://python-poetry.org/docs/cli/#install"><code>poetry install</code> documentation</a> (python-poetry.org)</li>
<li><a href="https://python-poetry.org/docs/cli/#build"><code>poetry build</code> documentation</a> (python-poetry.org)</li>
<li><a href="https://python-poetry.org/docs/pyproject/#poetry-and-pep-517">Poetry and PEP 517</a> (python-poetry.org)</li>
</ul>
<h2 id="poetry-version-vs-caching">Application version changes can lead to slow rebuilds</h2>
<p>If you’re using Poetry in its default configuration, your package/application version is stored in <code>pyproject.toml</code>. That means that every time you change the version, <code>pyproject.toml</code> will change. Which means you’ll have to reinstall dependencies from scratch when you rebuild your Docker image, even if the dependencies haven’t changed: the new <code>pyproject.toml</code> will invalidate the Docker build cache.</p>
<p>How can you fix this?</p>
<p>First, you can choose not to care. If you don’t update application versions very often, re-installing all dependencies on a image build won’t happen that often.</p>
<p>Second, you can choose not to rely on Poetry’s application versioning. Either you can choose not to set versions at all for your package, or you can use something like the <code>poetry-dynamic-versioning</code> package that lets you set versions from Git tags (or some other version control). This introduces a dependency on your Git repository during Docker build time, which has its own set of issues (<a href="#git-dockerignore">ref</a>).</p>
<p>Third, you can install dependencies via <code>pip</code>. Outside of your Docker build, in your build script, you can run <code>poetry export</code> to dump the dependencies to a <code>requirements.txt</code> file:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true"></a><span class="co"># Install the plugin needed to run export:</span></span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true"></a><span class="ex">poetry</span> self add poetry-plugin-export</span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true"></a><span class="co"># Create the requirements.txt:</span></span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true"></a><span class="ex">poetry</span> export -o requirements.txt</span>
<span id="cb130-6"><a href="#cb130-6" aria-hidden="true"></a><span class="ex">docker</span> image build -t myimage .</span></code></pre></div>
<p>In your <code>Dockerfile</code> you can then install dependencies using <code>pip</code>:</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true"></a></span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true"></a><span class="co"># etc..</span></span></code></pre></div>
<p>You can also do a multi-stage build where the first stage installs Poetry and does the export.</p>
<h3 id="references-62">References</h3>
<ul>
<li><a href="https://github.com/mtkennerly/poetry-dynamic-versioning"><code>poetry-dynamic-versioning</code></a> (github.com)</li>
<li><a href="https://github.com/python-poetry/poetry-plugin-export"><code>poetry-plugin-export</code></a> (github.com)</li>
</ul>
<h1 id="multi-stage">Best practices: Multi-stage builds</h1>
<h2 id="omit-build-dependencies-from-your-runtime-image">Omit build dependencies from your runtime image</h2>
<p>If you need to use a compiler to build some of your packages, installing the compiler will make your image much bigger. But that compiler isn’t necessary when running the image, it’s only necessary during the build phase.</p>
<p>One solution is multi-stage builds: create a series of images, the first with all the packages necessary to build your image, and the second with only the runtime packages installed. As you build the runtime image, you can copy files from the build image:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true"></a><span class="co"># This is the first image:</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true"></a><span class="kw">FROM</span> ubuntu:18.04 AS compile-image</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update</span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true"></a><span class="kw">RUN</span> apt-get install -y --no-install-recommends gcc build-essential</span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true"></a></span>
<span id="cb132-6"><a href="#cb132-6" aria-hidden="true"></a><span class="kw">WORKDIR</span> /root</span>
<span id="cb132-7"><a href="#cb132-7" aria-hidden="true"></a><span class="kw">COPY</span> hello.c .</span>
<span id="cb132-8"><a href="#cb132-8" aria-hidden="true"></a><span class="kw">RUN</span> gcc -o helloworld hello.c</span>
<span id="cb132-9"><a href="#cb132-9" aria-hidden="true"></a></span>
<span id="cb132-10"><a href="#cb132-10" aria-hidden="true"></a><span class="co"># This is the second and final image; it copies the compiled</span></span>
<span id="cb132-11"><a href="#cb132-11" aria-hidden="true"></a><span class="co"># binary over but starts from the base ubuntu:18.04 image.</span></span>
<span id="cb132-12"><a href="#cb132-12" aria-hidden="true"></a><span class="kw">FROM</span> ubuntu:18.04 AS runtime-image</span>
<span id="cb132-13"><a href="#cb132-13" aria-hidden="true"></a></span>
<span id="cb132-14"><a href="#cb132-14" aria-hidden="true"></a><span class="kw">COPY</span> --from=compile-image /root/helloworld .</span>
<span id="cb132-15"><a href="#cb132-15" aria-hidden="true"></a><span class="kw">CMD</span> [<span class="st">&quot;./helloworld&quot;</span>]</span></code></pre></div>
<p>Notice that each step has a name, <code>compile-image</code> and <code>runtime-image</code>.</p>
<p>If you just build normally, both stages will get built but any tags will get set on the final stage, in this case <code>runtime-image</code>. But you can also build specific stages, so if for example you to build the <code>compile-image</code> and then give it a tag you can do:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true"></a>$ <span class="ex">docker</span> build --target compile-image -t myimage:compile-stage .</span></code></pre></div>
<p>In Docker Compose, you can also have <code>build</code> services target a particular stage.</p>
<h3 id="references-63">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/smaller-python-docker-images/">Multi-stage builds: Smaller images for compiled code</a> (pythonspeed.com) motivates the problem</li>
<li><a href="https://docs.docker.com/develop/develop-images/multistage-build/">Multi-stage builds</a> (docs.docker.com)</li>
<li><a href="https://docs.docker.com/compose/compose-file/#target">Targeting multi-stage builds in Docker Compose</a> (docs.docker.com)</li>
</ul>
<h2 id="use-a-virtualenv-to-make-copying-across-stages-easier">Use a virtualenv to make copying across stages easier</h2>
<p>If you’re creating a multi-stage Python Docker image, you need to figure out how to copy images from the build image to the runtime image. Python packages can install files in a variety of locations, so this can be tricky.</p>
<p>One way to do that is by installing everything in a virtualenv:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye AS compile-image</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true"></a><span class="kw">RUN</span> apt-get update</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true"></a><span class="kw">RUN</span> apt-get install -y --no-install-recommends build-essential gcc</span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true"></a></span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true"></a><span class="kw">RUN</span> python -m venv /opt/venv</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true"></a><span class="co"># Make sure we use the virtualenv:</span></span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true"></a><span class="kw">ENV</span> PATH=<span class="st">&quot;/opt/venv/bin:$PATH&quot;</span></span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true"></a></span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb134-10"><a href="#cb134-10" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb134-11"><a href="#cb134-11" aria-hidden="true"></a></span>
<span id="cb134-12"><a href="#cb134-12" aria-hidden="true"></a><span class="kw">COPY</span> setup.py .</span>
<span id="cb134-13"><a href="#cb134-13" aria-hidden="true"></a><span class="kw">COPY</span> myapp/ .</span>
<span id="cb134-14"><a href="#cb134-14" aria-hidden="true"></a><span class="kw">RUN</span> pip install .</span>
<span id="cb134-15"><a href="#cb134-15" aria-hidden="true"></a></span>
<span id="cb134-16"><a href="#cb134-16" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye AS build-image</span>
<span id="cb134-17"><a href="#cb134-17" aria-hidden="true"></a><span class="kw">COPY</span> --from=compile-image /opt/venv /opt/venv</span>
<span id="cb134-18"><a href="#cb134-18" aria-hidden="true"></a></span>
<span id="cb134-19"><a href="#cb134-19" aria-hidden="true"></a><span class="co"># Make sure we use the virtualenv:</span></span>
<span id="cb134-20"><a href="#cb134-20" aria-hidden="true"></a><span class="kw">ENV</span> PATH=<span class="st">&quot;/opt/venv/bin:$PATH&quot;</span></span>
<span id="cb134-21"><a href="#cb134-21" aria-hidden="true"></a><span class="kw">CMD</span> [<span class="st">&#39;myapp&#39;</span>]</span></code></pre></div>
<p>Another way is to use <code>pip install --user</code>, and then you just need to copy over the <code>~/.local</code> directory where user installs happen.</p>
<h3 id="references-64">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/multi-stage-docker-python/">Multi-stage builds, Python specifics: <code>virtualenv</code>, <code>-–user</code>, and other methods</a> (pythonspeed.com)</li>
</ul>
<h2 id="avoid-unnecessary-complete-rebuilds">Avoid unnecessary complete rebuilds</h2>
<p>One problem with multi-stage builds is rebuilds. If you only stored the final runtime image, you won’t have the build/compile-stage image available when you rebuild. Which means you won’t get any benefit from Docker build caching: every rebuild will rebuild from scratch.</p>
<p>The solution is to tag both images, the compile-stage and the runtime-stage, and to store them both:</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true"></a><span class="co">#!/bin/bash</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true"></a><span class="kw">set</span> <span class="ex">-euo</span> pipefail</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true"></a><span class="co"># Pull the latest version of the image, in order to</span></span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true"></a><span class="co"># populate the build cache:</span></span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true"></a><span class="ex">docker</span> pull itamarst/helloworld:compile-stage <span class="kw">||</span> <span class="fu">true</span></span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true"></a><span class="ex">docker</span> pull itamarst/helloworld:latest        <span class="kw">||</span> <span class="fu">true</span></span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true"></a></span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true"></a><span class="co"># Build the runtime stage, using cached compile stage:</span></span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true"></a><span class="ex">docker</span> build --target runtime-image <span class="kw">\</span></span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true"></a>       <span class="ex">--cache-from</span>=itamarst/helloworld:compile-stage <span class="kw">\</span></span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true"></a>       <span class="ex">--cache-from</span>=itamarst/helloworld:latest <span class="kw">\</span></span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true"></a>       <span class="ex">--tag</span> itamarst/helloworld:latest .</span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true"></a></span>
<span id="cb135-14"><a href="#cb135-14" aria-hidden="true"></a><span class="co"># Build the compile stage so we tag it. In practice this will</span></span>
<span id="cb135-15"><a href="#cb135-15" aria-hidden="true"></a><span class="co"># all come from the local cache and run quickly.</span></span>
<span id="cb135-16"><a href="#cb135-16" aria-hidden="true"></a><span class="ex">docker</span> build --target compile-image <span class="kw">\</span></span>
<span id="cb135-17"><a href="#cb135-17" aria-hidden="true"></a>       <span class="ex">--cache-from</span>=itamarst/helloworld:latest <span class="kw">\</span></span>
<span id="cb135-18"><a href="#cb135-18" aria-hidden="true"></a>       <span class="ex">--cache-from</span>=itamarst/helloworld:compile-stage <span class="kw">\</span></span>
<span id="cb135-19"><a href="#cb135-19" aria-hidden="true"></a>       <span class="ex">--tag</span> itamarst/helloworld:compile-stage .</span>
<span id="cb135-20"><a href="#cb135-20" aria-hidden="true"></a></span>
<span id="cb135-21"><a href="#cb135-21" aria-hidden="true"></a><span class="co"># Push the new versions:</span></span>
<span id="cb135-22"><a href="#cb135-22" aria-hidden="true"></a><span class="ex">docker</span> push itamarst/helloworld:compile-stage</span>
<span id="cb135-23"><a href="#cb135-23" aria-hidden="true"></a><span class="ex">docker</span> push itamarst/helloworld:latest</span></code></pre></div>
<p>We build the runtime stage first to enable parallelism when using BuildKit; see the next best practice.</p>
<h3 id="references-65">References</h3>
<ul>
<li><a href="https://pythonspeed.com/articles/faster-multi-stage-builds/">Multi-stage builds: Why your build is surprisingly slow, and how to speed it up</a> (pythonspeed.com)</li>
</ul>
<h2 id="optional-use-buildkit-for-faster-builds">Optional: Use BuildKit for faster builds</h2>
<p>BuildKit is a new build backend for Docker. Among other features, if you’re doing multi-stage builds it can build the different stages in parallel, insofar as this is possible. That means BuildKit can make multi-stage builds run faster, especially if you build the runtime stage first (see above).</p>
<p>You can enable BuildKit by adding:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true"></a><span class="bu">export</span> <span class="va">DOCKER_BUILDKIT=</span>1</span></code></pre></div>
<p>to the top of your build script.</p>
<h2 id="optional-optimizing-image-size-even-further">Optional: Optimizing image size even further</h2>
<p>A multi-stage build gives you the opportunity to make your runtime image even smaller, by deleting arbitrary files from the build stage. Remember that because of layering, deleting files with a <code>RUN</code> command won’t make the build-stage image smaller. It will however let you copy over less files.</p>
<p>Some examples of files you might want to delete:</p>
<ul>
<li>Source code in C or another compiled language that is in a directory you plan to copy over, now that you’re done compiling it.</li>
<li>Likewise, any build artifacts.</li>
<li><code>.pyc</code> files, but only if you’re OK with slower startup.</li>
<li>JavaScript source map files, if you don’t care about the additional debugging they enable.</li>
</ul>
<p>Your <code>Dockerfile</code> might therefore look like this:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye AS compile-image</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true"></a></span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true"></a><span class="kw">RUN</span> python -m venv /venv</span>
<span id="cb137-4"><a href="#cb137-4" aria-hidden="true"></a><span class="kw">ENV</span> PATH=<span class="st">&quot;/venv/bin:$PATH&quot;</span></span>
<span id="cb137-5"><a href="#cb137-5" aria-hidden="true"></a><span class="kw">COPY</span> requirements.txt .</span>
<span id="cb137-6"><a href="#cb137-6" aria-hidden="true"></a><span class="kw">RUN</span> pip install -r requirements.txt</span>
<span id="cb137-7"><a href="#cb137-7" aria-hidden="true"></a></span>
<span id="cb137-8"><a href="#cb137-8" aria-hidden="true"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb137-9"><a href="#cb137-9" aria-hidden="true"></a><span class="kw">COPY</span> . .</span>
<span id="cb137-10"><a href="#cb137-10" aria-hidden="true"></a><span class="kw">RUN</span> python setup.py build_ext --inplace</span>
<span id="cb137-11"><a href="#cb137-11" aria-hidden="true"></a></span>
<span id="cb137-12"><a href="#cb137-12" aria-hidden="true"></a><span class="co"># Delete C, Cython, map files and build artifacts we</span></span>
<span id="cb137-13"><a href="#cb137-13" aria-hidden="true"></a><span class="co"># don&#39;t want in the runtime image:</span></span>
<span id="cb137-14"><a href="#cb137-14" aria-hidden="true"></a><span class="kw">RUN</span> rm -f `find . -iname <span class="st">&quot;*.c&quot;</span>` &amp;&amp; \</span>
<span id="cb137-15"><a href="#cb137-15" aria-hidden="true"></a>    rm -f `find . -iname <span class="st">&quot;*.pyx&quot;</span>` &amp;&amp; \</span>
<span id="cb137-16"><a href="#cb137-16" aria-hidden="true"></a>    rm -f `find /venv -iname <span class="st">&quot;*.js.map&quot;</span>` &amp;&amp; \</span>
<span id="cb137-17"><a href="#cb137-17" aria-hidden="true"></a>    rm -f build/</span>
<span id="cb137-18"><a href="#cb137-18" aria-hidden="true"></a></span>
<span id="cb137-19"><a href="#cb137-19" aria-hidden="true"></a><span class="kw">FROM</span> python:3.10-slim-bullseye AS build-image</span>
<span id="cb137-20"><a href="#cb137-20" aria-hidden="true"></a><span class="kw">COPY</span> --from=compile-image /opt/venv /opt/venv</span>
<span id="cb137-21"><a href="#cb137-21" aria-hidden="true"></a><span class="kw">COPY</span> --from=compile-image /app /app</span>
<span id="cb137-22"><a href="#cb137-22" aria-hidden="true"></a></span>
<span id="cb137-23"><a href="#cb137-23" aria-hidden="true"></a><span class="co"># ... etc. ...</span></span></code></pre></div>
<h1 class="unnumbered" id="some-final-recommendations">Some final recommendations</h1>
<p>There are many best practices, and you won’t need all of them, especially not to begin with. So start by following <a href="#plan">the plan in the first chapter</a> and see how much you actually need in practice.</p>
<p>If you’d like a working setup implementing many of these best practices, either as an example or as a basis for your packaging, you can also purchase <a href="https://pythonspeed.com/products/pythoncontainer/">a production-ready template for Pip, Poetry, or Pipenv-based projects</a> that will allow you to get going in just an hour or two. You can also purchase <a href="https://pythonspeed.com/products/condacontainer/">a template designed for Conda</a>. As a purchaser of the handbook, you can use the discount code <code>BPQUICKSTART</code> to get a 15% discount off the templates.</p>
<p>And as always, if you have any questions or suggestions, please email me at <a href="mailto:itamar@pythonspeed.com">itamar@pythonspeed.com</a>.</p>
<p>—Itamar Turner-Trauring</p>
<h1 class="unnumbered" id="changelog">Changelog</h1>
<h3 class="unnumbered" id="september-19-2022">September 19, 2022</h3>
<p>Updates:</p>
<ul>
<li>Trivy v0.23 is now out, fixing remaining commercial usage issues; it also adds support for Alma Linux and RockyLinux.</li>
<li><code>conda-lock</code> supports <code>pip</code> packages too in its released version, and has a new file format.</li>
<li>Podman supports build secrets and mount caches.</li>
<li>Poetry 1.2 update: new installer, plus <code>poetry-plugin-export</code> is now separate.</li>
<li>Support for Pipenv 2022.4.8 and later: new <code>pipenv requirements</code> command.</li>
<li>Ubuntu 22.04, RHEL 9.</li>
<li>Latest BuildKit backend is now v1.4.</li>
<li>Switched examples to Python 3.10 instead of 3.9.</li>
<li>PEP 656 means Alpine-compatible wheels are starting to become available.</li>
<li>Compose v2 has initial support for build secrets.</li>
</ul>
<p>More best practices:</p>
<ul>
<li>Scanning for leaked secrets.</li>
<li>Dealing with new ARM (“Silicon”/M1/M2) Macs.</li>
</ul>
<h3 class="unnumbered" id="january-26-2022">January 26, 2022</h3>
<ul>
<li>New best practices:
<ul>
<li>Security scans for Conda with Jake.</li>
<li>CentOS alternatives.</li>
</ul></li>
<li>Fix <code>conda activate</code> in the face of scripts with semi-broken activation scripts, by disabling bash strict mode.</li>
<li>Update with some changes to <code>trivy</code> security scanner.</li>
<li>Removed the <code>safety</code> security scanner, since the non-commercial usage restriction is too limiting.</li>
<li>Note that <code>conda-lock</code> will support pip packages in the near future.</li>
</ul>
<h3 class="unnumbered" id="august-31-2021">August 31, 2021</h3>
<ul>
<li>Debian “Bullseye” 11 has replaced Buster as the stable Debian of choice.</li>
<li>Latest BuildKit backend is now v1.3.</li>
<li>Documented <code>tini -g</code>.</li>
<li>Added note on dealing with <code>pip</code> packages when using <code>conda-lock</code>.</li>
<li>New best practices:
<ul>
<li>Conda environments require activation.</li>
<li>Faster Conda installs with Mamba.</li>
</ul></li>
</ul>
<h3 class="unnumbered" id="june-7-2021">June 7, 2021</h3>
<ul>
<li>Clarified <code>STOPSIGNAL</code> usage.</li>
</ul>
<h3 class="unnumbered" id="june-1-2021">June 1, 2021</h3>
<ul>
<li>Added best practices:
<ul>
<li>Don’t leak secret files.</li>
<li>Don’t leak runtime secrets.</li>
<li>Don’t store temporary files in layers.</li>
<li>Get rid of unneeded files.</li>
</ul></li>
<li>Added <code>--nodocs</code> to <code>dnf</code> instructions, for even smaller images.</li>
<li>Added an alternative method for activating Conda environments.</li>
</ul>
<h3 class="unnumbered" id="march-16-2021">March 16, 2021</h3>
<ul>
<li>When using BuildKit you should <em>always</em> set <code>--build-arg BUILDKIT_INLINE_CACHE=1</code> if you want <code>--cache-from</code> to work.</li>
<li>Noted that official Python Docker image is slower than Ubuntu.</li>
</ul>
<h3 class="unnumbered" id="february-8-2021">February 8, 2021</h3>
<ul>
<li>The Quickstart has been renamed to the Handbook; at 100 pages, it’s getting more than just introductory.</li>
<li>New best practices:
<ul>
<li>Installing packages with <code>pipenv</code> without exporting.</li>
<li>Keeping <code>pipenv</code> separate from application code.</li>
<li>Recommend <code>docker build --label</code> over <code>LABEL</code>.</li>
</ul></li>
</ul>
<h3 class="unnumbered" id="february-3-2021">February 3, 2021</h3>
<ul>
<li>Removed references to CentOS, as it is no longer a stable base image.</li>
<li>Added link to RedHat’s Docker base image.</li>
<li>Noted Podman can be used with BuildKit.</li>
<li>Noted need for <code>--keep-outdated</code> when using <code>pipenv lock</code>.</li>
<li>Documented how to make Docker Compose use BuildKit.</li>
<li>New best practices:
<ul>
<li>Caching package downloads across builds using BuildKit.</li>
<li>Avoiding dev dependency installs in Poetry.</li>
<li>Conda dependency locking using <code>conda-lock</code>.</li>
</ul></li>
</ul>
<h3 class="unnumbered" id="january-28-2021">January 28, 2021</h3>
<ul>
<li>Noted need to pass <code>--no-capture-output</code> to <code>conda run</code> (thanks to Joe Selvik).</li>
</ul>
<h3 class="unnumbered" id="december-17-2020">December 17, 2020</h3>
<p>Updates for Docker 20.10 and a stable BuildKit.</p>
<ul>
<li>Added new chapter covering different Docker releases and BuildKit.</li>
<li>Switched all BuildKit examples to use the new stable <code>docker/dockerfile:1.2</code> version.</li>
<li>Documented getting BuildKit secrets from environment variables.</li>
</ul>
<h3 class="unnumbered" id="november-13-2020">November 13, 2020</h3>
<ul>
<li>Documented PEP 517 Poetry installation usage.</li>
<li>A large number of minor code fixes throughout, as well as some typos in the text.</li>
<li>HTML version is now included, for easier copy/pasting.</li>
<li>Noted an issue with Conda-Pack that will hopefully be fixed soon.</li>
</ul>
<h3 class="unnumbered" id="october-22-2020">October 22, 2020</h3>
<ul>
<li>Expanded and more accurate Poetry two-step install, plus added three more Poetry-related best practices.</li>
<li>Added best practice on adding <code>.git</code> to <code>.dockerignore</code>, and what to do when you can’t.</li>
</ul>
<h3 class="unnumbered" id="september-22-2020">September 22, 2020</h3>
<p>Added best practices:</p>
<ul>
<li>Using <code>conda clean</code> for smaller Conda-based Docker images.</li>
<li>Using OpenBLAS instead of MKL for smaller Docker images.</li>
<li>Using <code>conda-pack</code> and multi-stage builds for even smaller Conda-based Docker images.</li>
</ul>
<p>Noted that the <code>safety</code> vulnerability scanner is not licensed for commercial use.</p>
<h3 class="unnumbered" id="june-17-2020">June 17, 2020</h3>
<p>More best practices:</p>
<ul>
<li>Various BuildKit features that help speed up builds.</li>
<li>Dropping capabilities.</li>
<li>Avoiding listening on ports &lt; 1024.</li>
<li>Running a different command altogether based on command-line arguments.</li>
<li>Bytecode compilation.</li>
<li>Additional image size optimization in multi-stage builds.</li>
<li>Warm up the build cache for per-branch builds.</li>
<li>Requirements for running on Heroku and Google Cloud Run.</li>
<li>BuildKit ssh-agent forwarding.</li>
<li>BuildKit secrets when using Docker Compose.</li>
</ul>
<p>Other tweaks and improvements throughout the text.</p>
<h3 class="unnumbered" id="june-8-2020">June 8, 2020</h3>
<p>The Checklist has been renamed, and is now known as a Quickstart. To help make that change:</p>
<ul>
<li>Added a new introductory chapter with a plan to help you figure out which best practices to implement when.</li>
<li>Tweaked the chapter structure.</li>
</ul>
<p>Additionally:</p>
<ul>
<li>Added a best practice about using <code>dive</code> to find large layers.</li>
<li>Split off <code>init</code> into its own best practice.</li>
<li>Explained the goal of responding to health checks quickly more broadly, rather than in specific implementation terms of process/thread pool.</li>
<li>Added more nuance to the section on updating dependencies once a month.</li>
<li>Restored the Pipenv instructions, since it’s now being maintained again.</li>
<li>Make the <code>DEBIAN_FRONTEND=noninteractive</code> best practice standalone.</li>
</ul>
<h3 class="unnumbered" id="june-2-2020">June 2, 2020</h3>
<p>Added multiple new best practices:</p>
<ul>
<li>Making sure <code>ARG</code> doesn’t break build caching.</li>
<li>Don’t use the <code>latest</code> tag.</li>
<li>For better reproducibility, you can create a custom base image.</li>
<li>Size checks for images.</li>
<li>Security scanners: <code>bandit</code>, <code>safety</code>, <code>trivy</code>.</li>
</ul>
<p>Also updated existing best practices:</p>
<ul>
<li>You can make a build arg available at runtime by using <code>ENV</code>.</li>
<li>For build secrets another alternative is short term keys.</li>
</ul>
<h3 class="unnumbered" id="april-27-2020">April 27, 2020</h3>
<ul>
<li>Added new best practice on timely security updates, with additional information on automatic notifications.</li>
<li>Switched some examples from shell session transcripts to <code>Dockerfile</code> or shell script.</li>
<li>Noted <code>docker build</code> and Docker Compose support for targeting named stages.</li>
</ul>
<h3 class="unnumbered" id="april-1-2020">April 1, 2020</h3>
<ul>
<li>Documented two-stage install with Poetry.</li>
<li>Added link to <a href="https://github.com/willfarrell/docker-autoheal">docker-autoheal</a>.</li>
</ul>
<h3 class="unnumbered" id="february-24-2020">February 24, 2020</h3>
<p>Added many more examples:</p>
<ul>
<li>Configuring <code>logging</code>.</li>
<li>A smoke test.</li>
<li>Passing in secrets with BuildKit.</li>
<li><code>.dockerignore</code> file.</li>
<li>System package upgrade script for CentOS/RHEL.</li>
<li><code>Dockerfile</code> healthcheck.</li>
<li>And a few more expanded examples here and there.</li>
</ul>
</body>
</html>
